{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "from tests.MOF_builder.functions.ciftemplate2graph import ct2g,node_vecs\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import os\n",
    "import veloxchem as vlx\n",
    "import re\n",
    "from numpy.linalg import norm\n",
    "from tests.MOF_builder.functions.bbcif_properties import bb2array,X_vecs,selected_type_vecs\n",
    "from tests.MOF_builder.functions.place_bbs import superimpose,mag_superimpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "center is two points\n",
      "[9, 14]\n",
      "ditopic linker: center are two points\n",
      "find connected X in edge:   24\n",
      "find connected X in edge:   39\n",
      "edges/diedge.cif is writen\n",
      "center_frag: 46 [18, 33]\n"
     ]
    }
   ],
   "source": [
    "from src.MOF_builder.functions.frag_recognizer import process_linker_molecule\n",
    "linker_file = 'ndi.xyz'\n",
    "molecule = vlx.Molecule.read_xyz_file(linker_file)\n",
    "linker_topic =2\n",
    "center_frag_nodes_num,center_Xs,single_frag_nodes_num,frag_Xs= process_linker_molecule(molecule,linker_topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nEr1     Er     0.8416   0.75   0.1586\\nEr2     Er     0.6584   0.75   0.3414\\nEr3     Er     0.8416   0.25   0.8414\\nEr4     Er     0.6584   0.25   0.6586\\nV5     V     0.5   0.5   0.5\\nV6     V     0.5   0.0   0.5\\nEr7     Er     0.1584   0.25   0.8414\\nEr8     Er     0.3416   0.25   0.6586\\nEr9     Er     0.1584   0.75   0.1586\\nEr10     Er     0.3416   0.75   0.3414\\nV11     V     0.0   0.0   0.0\\nV12     V     0.0   0.5   0.0\\nloop_\\n_geom_bond_atom_site_label_1\\n_geom_bond_atom_site_label_2\\n_geom_bond_distance\\n_geom_bond_site_symmetry_2\\n_ccdc_geom_bond_type\\nEr1     Er2    10.0   .     S\\nEr1     V11    10.0   1_665     S\\nEr1     V12    10.0   1_655     S\\nEr2     V5    10.0   .     S\\nEr2     V6    10.0   1_565     S\\nEr3     Er4    10.0   .     S\\nEr3     V12    10.0   1_656     S\\nEr3     V11    10.0   1_656     S\\nEr4     V5    10.0   .     S\\nEr4     V6    10.0   .     S\\nV5     V6    10.0   .     S\\nV5     V6    10.0   1_565     S\\nV5     Er8    10.0   .     S\\nV5     Er10    10.0   .     S\\nV6     V5    10.0   1_545     S\\nV6     Er8    10.0   .     S\\nV6     Er2    10.0   1_545     S\\nV6     Er10    10.0   1_545     S\\nEr7     Er8    10.0   .     S\\nEr7     V11    10.0   1_556     S\\nEr7     V12    10.0   1_556     S\\nEr9     Er10    10.0   .     S\\nEr9     V11    10.0   1_565     S\\nEr9     V12    10.0   .     S\\nEr10     V6    10.0   1_565     S\\nV11     V12    10.0   1_545     S\\nV11     Er1    10.0   1_445     S\\nV11     V12    10.0   .     S\\nV11     Er3    10.0   1_454     S\\nV11     Er9    10.0   1_545     S\\nV11     Er7    10.0   1_554     S\\nV12     V11    10.0   1_565     S\\nV12     Er1    10.0   1_455     S\\nV12     Er3    10.0   1_454     S\\nV12     Er7    10.0   1_554     S\\n'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display edges of the graph\n",
    "\n",
    "\n",
    "'''\n",
    "Er1     Er     0.8416   0.75   0.1586\n",
    "Er2     Er     0.6584   0.75   0.3414\n",
    "Er3     Er     0.8416   0.25   0.8414\n",
    "Er4     Er     0.6584   0.25   0.6586\n",
    "V5     V     0.5   0.5   0.5\n",
    "V6     V     0.5   0.0   0.5\n",
    "Er7     Er     0.1584   0.25   0.8414\n",
    "Er8     Er     0.3416   0.25   0.6586\n",
    "Er9     Er     0.1584   0.75   0.1586\n",
    "Er10     Er     0.3416   0.75   0.3414\n",
    "V11     V     0.0   0.0   0.0\n",
    "V12     V     0.0   0.5   0.0\n",
    "loop_\n",
    "_geom_bond_atom_site_label_1\n",
    "_geom_bond_atom_site_label_2\n",
    "_geom_bond_distance\n",
    "_geom_bond_site_symmetry_2\n",
    "_ccdc_geom_bond_type\n",
    "Er1     Er2    10.0   .     S\n",
    "Er1     V11    10.0   1_665     S\n",
    "Er1     V12    10.0   1_655     S\n",
    "Er2     V5    10.0   .     S\n",
    "Er2     V6    10.0   1_565     S\n",
    "Er3     Er4    10.0   .     S\n",
    "Er3     V12    10.0   1_656     S\n",
    "Er3     V11    10.0   1_656     S\n",
    "Er4     V5    10.0   .     S\n",
    "Er4     V6    10.0   .     S\n",
    "V5     V6    10.0   .     S\n",
    "V5     V6    10.0   1_565     S\n",
    "V5     Er8    10.0   .     S\n",
    "V5     Er10    10.0   .     S\n",
    "V6     V5    10.0   1_545     S\n",
    "V6     Er8    10.0   .     S\n",
    "V6     Er2    10.0   1_545     S\n",
    "V6     Er10    10.0   1_545     S\n",
    "Er7     Er8    10.0   .     S\n",
    "Er7     V11    10.0   1_556     S\n",
    "Er7     V12    10.0   1_556     S\n",
    "Er9     Er10    10.0   .     S\n",
    "Er9     V11    10.0   1_565     S\n",
    "Er9     V12    10.0   .     S\n",
    "Er10     V6    10.0   1_565     S\n",
    "V11     V12    10.0   1_545     S\n",
    "V11     Er1    10.0   1_445     S\n",
    "V11     V12    10.0   .     S\n",
    "V11     Er3    10.0   1_454     S\n",
    "V11     Er9    10.0   1_545     S\n",
    "V11     Er7    10.0   1_554     S\n",
    "V12     V11    10.0   1_565     S\n",
    "V12     Er1    10.0   1_455     S\n",
    "V12     Er3    10.0   1_454     S\n",
    "V12     Er7    10.0   1_554     S\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.754259612561926 linker_length\n"
     ]
    }
   ],
   "source": [
    "#pillar stack structure:\n",
    "#regarding chain_node cif file:\n",
    "    #find the pillar direction vector which is defined by the Al-Al vectors in chain_node cif file \n",
    "    #find the pair of x vectors, which are vertical to the pillar direction vector in chain_node cif file, could be more than one pairs\n",
    "    #find the Al-Al length, read from the cif file\n",
    "#regarding the linker cif file:\n",
    "    #find the length of the linker which should be the maximum length of X vectors in the linker cif file\n",
    "\n",
    "#regarding the template cif file:\n",
    "    #find the pillar direction which should be along the pure V-V direction (no Er node between) in the template cif file, \n",
    "    #find the edge vector in the template cif file, which should be Er-Er edge\n",
    "    #find the length of the edge vector in the template cif file\n",
    "    #fix one direction of the box, which should be parallel to the pilalar direction\n",
    "\n",
    "#the unit_cell of the template cif file should be scaled to fit the length of the linker, and the box_vector which along pillar direction should be fixed\n",
    "#when we want to place the node in the box, we should use a pair of x vectors which targets the connected V through the edge vector in the template cif file and the pillar direction vector, we use superimpose function to rotate and place the node at the right position\n",
    "#when we want to place the edge in the box, we should consider all of the x vectors placed in box and find the connected connected x vectors in two sidde of the Er-Er edge, then we use superimpose function to rotate and place the edge at the right position \n",
    "from tests.MOF_builder.functions.bbcif_properties import bb2array,selected_type_vecs,calc_edge_len\n",
    "from tests.MOF_builder.functions.place_bbs import superimpose\n",
    "\n",
    "chain_node_cif = '21Alchain.cif'\n",
    "template_cif = 'chain_rna.cif'\n",
    "linker_cif = 'edges/diedge.cif'\n",
    "#chain node\n",
    "#Al_vecs = selected_type_vecs(chain_node_cif,'.', 'Al',False)\n",
    "#chain_node_vecs = bb2array(chain_node_cif,'.')\n",
    "#chain_node_coords = np.asarray([i[1] for i in chain_node_vecs])\n",
    "#metal_cvec = Al_vecs[0]-Al_vecs[1]\n",
    "#node_pillar_cvec = metal_cvec/norm(metal_cvec) \n",
    "#node_x_vecs = selected_type_vecs(chain_node_cif,'.','X',False)\n",
    "\n",
    "\n",
    "##find the x vectors which are vertical to the pillar direction\n",
    "#xx_pairs = []\n",
    "#for i in range(0,len(x_vecs)):\n",
    "#    for j in range(i+1,len(x_vecs)):\n",
    "#        xx_vec = x_vecs[i]-x_vecs[j]\n",
    "#        xx_vec = xx_vec/norm(xx_vec)\n",
    "#        if np.dot(xx_vec,metal_cvec) < 1e-3:\n",
    "#            xx_pairs.append((i,j))\n",
    "#print(xx_pairs)\n",
    "\n",
    "\n",
    "#linker\n",
    "linker_x_vecs = selected_type_vecs(linker_cif,'.','X',False)\n",
    "#ditopic linker only has two x vectors\n",
    "linker_length = calc_edge_len(linker_cif,'.') #length of the edge should be x-x length in linker cif file, unit angstrom\n",
    "print(linker_length,'linker_length')\n",
    "\n",
    "###template\n",
    "##gen = ct2g('chain_rna.cif', 'tests/templates')\n",
    "##net = next(gen)\n",
    "##TG, start, unit_cell, TVT, TET, TNAME, a, b, c, ang_alpha, ang_beta, ang_gamma, max_le, catenation = net\n",
    "##\n",
    "##def updateTG2NG(TG):\n",
    "##    #ditopic linker should be connected to two V nodes directly \n",
    "##    #find path between two nodes which starts from V node to V node passing through Er nodes\n",
    "##    Vnodes = [n for n in TG.nodes() if n.startswith('V')]\n",
    "##    Ernodes = [n for n in TG.nodes() if n.startswith('Er')]\n",
    "##\n",
    "##    valid_paths = []\n",
    "##    Vnodes = [n for n in TG.nodes() if n.startswith('V')]\n",
    "##    for i in range(0, len(Vnodes)):\n",
    "##        for j in range(i+1, len(Vnodes)):\n",
    "##            source=Vnodes[i]\n",
    "##            target=Vnodes[j]\n",
    "##            path = nx.shortest_path(TG, source,target)\n",
    "##            if len(path) > 2:\n",
    "##                #if only two V nodes are there in the path passed Er, then it is a valid path\n",
    "##                if all([n.startswith('Er') for n in path[1:-1]]):\n",
    "##                    valid_paths.append(path)\n",
    "##\n",
    "##    NG = nx.Graph()\n",
    "##    edges_info=TG.edges(data=True)\n",
    "##    count = 0\n",
    "##    le=0\n",
    "##    pillars_cvecs = []\n",
    "##    pillars_fvecs = []\n",
    "##    edge_cvecs = []\n",
    "##    edge_fvecs = []\n",
    "##    for edge in edges_info:\n",
    "##        #node1,node2=edge[0],edge[1]\n",
    "##        edge_type=edge[2]['type']\n",
    "##        edge_label=edge[2]['label']\n",
    "##        edge_ccoord=edge[2]['ccoords']\n",
    "##        edge_fcoord=edge[2]['fcoords']\n",
    "##        edge_length=edge[2]['length']\n",
    "##        edge_index=edge[2]['index']\n",
    "##        edge_pd = edge[2]['pd']\n",
    "##        node1,node2 = edge_pd\n",
    "##    \n",
    "##        if edge_type[0]==edge_type[1]:\n",
    "##            #V-V find the pillar direction which should be along the pure V-V direction (no Er node between) in the template cif file\n",
    "##            if edge_type[0]=='V':# chain of metal nodes\n",
    "##                #print(node1,node2,edge_type,edge_fcoord,edge_length,edge_index,edge_pd)\n",
    "##                #name = node1+node2+'_'+str(count)\n",
    "##                name = int(count)\n",
    "##                pillars_cvecs.append(TG.nodes[node1]['ccoords']-TG.nodes[node2]['ccoords'])\n",
    "##                pillars_fvecs.append(TG.nodes[node1]['fcoords']-TG.nodes[node2]['fcoords'])\n",
    "##                NG.add_node(name, label = (node1,node2),type=edge_type, index=edge_index, ccoords=edge_ccoord, fcoords=edge_fcoord, cn=[], cifname=[])\n",
    "##                count+=1\n",
    "##            #Er-Er find the edge vector in the template cif file, which should be Er-Er edge\n",
    "##            else:\n",
    "##                le = max(edge_length,le) #find the length of the edge vector in the template cif file\n",
    "##                edge_cvecs.append(TG.nodes[node1]['ccoords']-TG.nodes[node2]['ccoords'])\n",
    "##                edge_fvecs.append(TG.nodes[node1]['fcoords']-TG.nodes[node2]['fcoords'])\n",
    "##                pass\n",
    "##                #edge direction \n",
    "##                #print(node1,node2,edge_type,edge_fcoord,edge_length,edge_index,edge_pd)\n",
    "##                #get evecs\n",
    "##\n",
    "##        else:\n",
    "##            #ignore Er-V\n",
    "##            #print(node1,node2,edge_type)\n",
    "##            pass\n",
    "##\n",
    "##    #in NG any VV node has 'V5' should be connected to antoher VV node with 'V11' and 'V12'\n",
    "##    for path in valid_paths:\n",
    "##        source = path[0]\n",
    "##        target = path[-1]\n",
    "##        #in NG any VV node has source should be connected to antoher VV node with target\n",
    "##        vv_source_nodes = [node for node in NG.nodes() if source in NG.nodes[node]['label']]\n",
    "##        vv_target_nodes = [node for node in NG.nodes() if target in NG.nodes[node]['label']]\n",
    "##        #connect any source node to any target node\n",
    "##\n",
    "##\n",
    "##    #find the pillar direction which should be along the pure V-V direction (no Er node between) in the template cif file\n",
    "##    count = 1\n",
    "##    edges_cvecs=[]\n",
    "##    edges_fvecs=[]\n",
    "##    for vv_source_node in vv_source_nodes:\n",
    "##        for vv_target_node in vv_target_nodes:\n",
    "##            fcoord = (NG.nodes[vv_source_node]['fcoords'],NG.nodes[vv_target_node]['fcoords'])\n",
    "##            ccoord = (NG.nodes[vv_source_node]['ccoords'],NG.nodes[vv_target_node]['ccoords'])\n",
    "##            edges_cvecs.append(NG.nodes[vv_target_node]['ccoords']- NG.nodes[vv_source_node]['ccoords'])\n",
    "##            edges_fvecs.append(NG.nodes[vv_target_node]['fcoords']- NG.nodes[vv_source_node]['fcoords'])\n",
    "##            lbl = [0,0,0]\n",
    "##            NG.add_edge(vv_source_node,vv_target_node,key=(count,lbl[0],lbl[1],lbl[2]), label=lbl , length=le, fcoords=fcoord, ccoords=ccoord, index=count, pd=(vv_source_node,vv_target_node))\n",
    "##            count+=1\n",
    "##    return NG,pillars_cvecs\n",
    "####\n",
    "####NG,pillars_cvecs = updateTG2NG(TG)\n",
    "#####fix one direction of the box, which should be parallel to the pilalar direction\n",
    "####\n",
    "####\n",
    "####\n",
    "#####the unit_cell of the template cif file should be scaled to fit the length of the linker, and the box_vector which along pillar direction should be fixed\n",
    "####\n",
    "####\n",
    "#####find the pillar direction which should be along the pure V-V direction (no Er node between) in the template cif file\n",
    "####\n",
    "##\n",
    "###find the pillar direction which should be along the pure V-V direction (no Er node between) in the template cif file\n",
    "##\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apply 7 symmetry operation\n",
      "0  no symmetry operation\n",
      "apply 7 symmetry operation\n",
      "0  no symmetry operation\n"
     ]
    }
   ],
   "source": [
    "from tests.MOF_builder.functions._readcif import extract_type_atoms_array_in_primitive_cell,read_cif,extract_atoms_xyz_from_lines,extract_quote_lines,extract_symmetry_operation_from_lines,apply_sym_operator\n",
    "import numpy as np\n",
    "\n",
    "target_type = 'Al'\n",
    "cell_info, array_atom, array_target_atoms=extract_type_atoms_array_in_primitive_cell(chain_node_cif, target_type)\n",
    "_,_, node_x_vecs=extract_type_atoms_array_in_primitive_cell(chain_node_cif, 'X')\n",
    "\n",
    "cell_info, symmetry_sector, atom_site_sector = read_cif(chain_node_cif)\n",
    "array_atom, array_xyz = extract_atoms_xyz_from_lines(atom_site_sector)\n",
    "node_com = np.mean(array_target_atoms, axis=0)\n",
    "chain_node_fcoords = array_xyz - node_com\n",
    "\n",
    "metal_cvec = array_target_atoms[0]-array_target_atoms[1]\n",
    "node_pillar_cvec = metal_cvec/norm(metal_cvec) \n",
    "node_x_vecs = node_x_vecs - node_com\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "from tests.MOF_builder.functions._readcif import extract_type_atoms_array_in_primitive_cell\n",
    "from scipy.spatial.distance import pdist\n",
    "from scipy.cluster.hierarchy import linkage\n",
    "from scipy.cluster.hierarchy import fcluster\n",
    "\n",
    "cif_file ='MIL53templatecif.cif'\n",
    "target_type = 'YY'\n",
    "cluster_distance_threshhold = 0.1\n",
    "\n",
    "# use cell_info to generate the matrix for the unit cell to get cartesian coordinates\n",
    "def make_supercell_3x3x3(array_xyz):\n",
    "    array_x1 = array_xyz + np.array([1, 0, 0])\n",
    "    array_x2 = array_xyz + np.array([-1, 0, 0])\n",
    "    array_y1 = array_xyz + np.array([0, 1, 0])\n",
    "    array_y2 = array_xyz + np.array([0, -1, 0])\n",
    "    array_x1_y1 = array_xyz + np.array([1, 1, 0])\n",
    "    array_x1_y2 = array_xyz + np.array([1, -1, 0])\n",
    "    array_x2_y1 = array_xyz + np.array([-1, 1, 0])\n",
    "    array_x2_y2 = array_xyz + np.array([-1, -1, 0])\n",
    "    \n",
    "    layer_3x3 = np.vstack((\n",
    "        array_xyz,\n",
    "        array_x1,\n",
    "        array_x2,\n",
    "        array_y1,\n",
    "        array_y2,\n",
    "        array_x1_y1,\n",
    "        array_x1_y2,\n",
    "        array_x2_y1,\n",
    "        array_x2_y2\n",
    "    ))\n",
    "    \n",
    "    layer_3x3_z1 = layer_3x3 + np.array([0, 0, 1])\n",
    "    layer_3x3_z2 = layer_3x3 + np.array([0, 0, -1])\n",
    "    \n",
    "    supercell_3x3x3 = np.vstack((\n",
    "        layer_3x3,\n",
    "        layer_3x3_z1,\n",
    "        layer_3x3_z2\n",
    "    ))\n",
    "    \n",
    "    return supercell_3x3x3\n",
    "\n",
    "def extract_unit_cell(cell_info):\n",
    "    pi = np.pi\n",
    "    aL, bL, cL, alpha, beta, gamma = cell_info\n",
    "    aL,bL,cL,alpha,beta,gamma = list(map(float, (aL,bL,cL,alpha,beta,gamma)))\n",
    "    ax = aL\n",
    "    ay = 0.0\n",
    "    az = 0.0\n",
    "    bx = bL * np.cos(gamma * pi / 180.0)\n",
    "    by = bL * np.sin(gamma * pi / 180.0)\n",
    "    bz = 0.0\n",
    "    cx = cL * np.cos(beta * pi / 180.0)\n",
    "    cy = (cL * bL * np.cos(alpha * pi /180.0) - bx * cx) / by\n",
    "    cz = (cL ** 2.0 - cx ** 2.0 - cy ** 2.0) ** 0.5\n",
    "    unit_cell = np.asarray([[ax,ay,az],[bx,by,bz],[cx,cy,cz]]).T\n",
    "    return unit_cell\n",
    "# a function, given an array of atoms, use distance to find the clusters of atoms, and return the center of the cluster, we can set a distance thereshold to define the cluster\n",
    "def find_cluster_center(array_atom):\n",
    "    array_atom = np.array(array_atom,dtype=float)\n",
    "    center = np.mean(array_atom,axis=0)\n",
    "    return center\n",
    "\n",
    "def clust_analysis_points(array_atom,distance_threshhold):\n",
    "    #use scipy.cluster distance, to cluster the points\n",
    "    #find the distance matrix\n",
    "    dist = pdist(array_atom)\n",
    "    #find the linkage matrix\n",
    "    Z = linkage(dist, 'ward')\n",
    "    #find the cluster\n",
    "    cluster = fcluster(Z, distance_threshhold, criterion='distance')\n",
    "    #find the center of the cluster\n",
    "    cluster_center = []\n",
    "    for i in range(1,max(cluster)+1):\n",
    "        cluster_center.append(find_cluster_center(array_atom[cluster==i]))\n",
    "    return cluster_center\n",
    "\n",
    "def extract_cluster_center_from_templatecif(cif_file, target_type,cluster_distance_threshhold):\n",
    "    cell_info, array_atom, array_target_atoms =extract_type_atoms_array_in_primitive_cell(cif_file, target_type)\n",
    "    unit_cell = extract_unit_cell(cell_info)\n",
    "    unit_cell = np.round(unit_cell,3)\n",
    "    metal333 = make_supercell_3x3x3(array_target_atoms)\n",
    "    metal333 = np.vstack(metal333)\n",
    "    #cluster analysis in cartesian coordinates\n",
    "    array_metal_ccords = np.dot(unit_cell,metal333.T).T\n",
    "    cluster_centers_ccoords=clust_analysis_points(array_metal_ccords,cluster_distance_threshhold)\n",
    "    cluster_centers_ccoords = np.vstack(cluster_centers_ccoords)\n",
    "    #cluster_centers should return fractional coordinates\n",
    "    cluster_centers_fcoords = np.dot(np.linalg.inv(unit_cell),cluster_centers_ccoords.T).T\n",
    "    #filter cluster centers which is inside the unit cell, boundary condition is [-0.01,1.01]\n",
    "    cluster_centers_fcoords = [c for c in cluster_centers_fcoords if all([i>=-0.01 and i<=1.01 for i in c])]\n",
    "    cluster_centers_fcoords = np.mod(cluster_centers_fcoords,1)\n",
    "    cluster_centers_fcoords = np.round(cluster_centers_fcoords,3)\n",
    "    cluster_centers_fcoords = np.unique(cluster_centers_fcoords,axis=0)\n",
    "    return cluster_centers_fcoords,cell_info,unit_cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apply 16 symmetry operation\n",
      "16  symmetry operation\n",
      "apply 16 symmetry operation\n",
      "16  symmetry operation\n"
     ]
    }
   ],
   "source": [
    "vvnode,cell_info,unit_cell = extract_cluster_center_from_templatecif(cif_file, 'YY',1)\n",
    "eenode,_,_ = extract_cluster_center_from_templatecif(cif_file, 'XX',1)\n",
    "\n",
    "#loop over super333xxnode and super333yynode to find the pair of x node in unicell which pass through the yynode\n",
    "vvnode333 = make_supercell_3x3x3(vvnode)\n",
    "eenode333 = make_supercell_3x3x3(eenode)\n",
    "#find pair of x, pass y, which means y is the edge center between two x \n",
    "\n",
    "#for each y, find nearest x in xxnode333, then check if the center of the pair of x is around y, if yes, the it is valid pair of x\n",
    "def check_inside_unit_cell(point):\n",
    "    return all([i>=-0.01 and i<=1.01 for i in point])\n",
    "\n",
    "#check if after np.mod, the fcoords is the same as before\n",
    "def check_moded_fcoords(point):\n",
    "    x,y,z = point[0],point[1],point[2]\n",
    "    if np.mod(x,1)!=x:\n",
    "        return False\n",
    "    if np.mod(y,1)!=y:\n",
    "        return False  \n",
    "    if np.mod(z,1)!=z:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def find_pair_v_e(vvnode333, eenode333):\n",
    "    G = nx.Graph()\n",
    "    pair_ve = []\n",
    "    for e in eenode333:\n",
    "        dist = np.linalg.norm(vvnode333 - e, axis=1)\n",
    "        # find two v which are nearest to e, and at least one v is in [0,1] unit cell\n",
    "        v1 = vvnode333[np.argmin(dist)]\n",
    "        v1_idx = np.argmin(dist)\n",
    "        dist[np.argmin(dist)] = 1000\n",
    "        v2 = vvnode333[np.argmin(dist)]\n",
    "        v2_idx = np.argmin(dist)\n",
    "        # find the center of the pair of v\n",
    "        center = (v1 + v2) / 2\n",
    "        # check if there is a v in [0,1] unit cell\n",
    "        if check_inside_unit_cell(v1) or check_inside_unit_cell(v2):\n",
    "            # check if the center of the pair of v is around e\n",
    "            if np.linalg.norm(center - e) < 1e-3:\n",
    "                G.add_node(v1_idx, fcoords=v1)\n",
    "                G.add_node(v2_idx, fcoords=v2)\n",
    "                G.add_edge(v1_idx, v2_idx, fcoords=(v1, v2),fc_center=e),\n",
    "                pair_ve.append((v1, v2, e))\n",
    "    return pair_ve, len(pair_ve), G\n",
    "\n",
    "#add ccoords to the the nodes in the graph\n",
    "def add_ccoords(G,unit_cell):\n",
    "    for n in G.nodes():\n",
    "        G.nodes[n]['ccoords'] = np.dot(unit_cell,G.nodes[n]['fcoords'])\n",
    "    return G\n",
    "\n",
    "def set_DV_V(G):\n",
    "    for n in G.nodes():\n",
    "        if G.degree(n) == max(dict(G.degree()).values()):\n",
    "            #G.nodes[n]['type'] = 'V'\n",
    "            #check if the moded ccoords is in the unit cell\n",
    "            if check_moded_fcoords(G.nodes[n]['fcoords']):\n",
    "                G.nodes[n]['type'] = 'V'\n",
    "            else:\n",
    "                G.nodes[n]['type'] = 'DV'\n",
    "        else:\n",
    "            G.nodes[n]['type'] = 'DV'\n",
    "    return G\n",
    "\n",
    "#check e in G, find e in unit_cell, use np.mod to filter the e in unit_cell, set the valid e with E type, others are DE type\n",
    "def set_DE_E(G):\n",
    "    all_e =[]\n",
    "    for e in G.edges():\n",
    "        all_e.append(G.edges[e]['fc_center'])\n",
    "    all_e = np.vstack(all_e)\n",
    "    all_e = np.mod(all_e,1)\n",
    "    unique_e = np.unique(all_e,axis=0)\n",
    "    for e in G.edges():\n",
    "        if np.any(np.all(np.isclose(G.edges[e]['fc_center'],unique_e),axis=1)):\n",
    "            G.edges[e]['type'] = 'E'\n",
    "        else:\n",
    "            G.edges[e]['type'] = 'DE'\n",
    "    return G\n",
    "\n",
    "\n",
    "\n",
    "pair_vv_e,_,G=find_pair_v_e(vvnode333,eenode333)\n",
    "G = add_ccoords(G,unit_cell)\n",
    "G = set_DV_V(G)\n",
    "G = set_DE_E(G)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 {'fcoords': array([0.  , 0.75, 0.25]), 'ccoords': array([ 0.     , 12.66975,  3.148  ]), 'type': 'V'} 2\n",
      "72 {'fcoords': array([ 0.  ,  0.25, -0.25]), 'ccoords': array([ 0.     ,  4.22325, -3.148  ]), 'type': 'DV'} 1\n",
      "2 {'fcoords': array([0.5 , 0.25, 0.75]), 'ccoords': array([3.3115 , 4.22325, 9.444  ]), 'type': 'V'} 2\n",
      "19 {'fcoords': array([ 0.5 , -0.25,  0.25]), 'ccoords': array([ 3.3115 , -4.22325,  3.148  ]), 'type': 'DV'} 1\n",
      "3 {'fcoords': array([0.5 , 0.75, 0.25]), 'ccoords': array([ 3.3115 , 12.66975,  3.148  ]), 'type': 'V'} 2\n",
      "5 {'fcoords': array([1.  , 0.75, 0.25]), 'ccoords': array([ 6.623  , 12.66975,  3.148  ]), 'type': 'DV'} 2\n",
      "76 {'fcoords': array([ 1.  ,  0.25, -0.25]), 'ccoords': array([ 6.623  ,  4.22325, -3.148  ]), 'type': 'DV'} 1\n",
      "84 {'fcoords': array([ 0.  ,  1.25, -0.25]), 'ccoords': array([ 0.     , 21.11625, -3.148  ]), 'type': 'DV'} 1\n",
      "14 {'fcoords': array([0.5 , 1.25, 0.75]), 'ccoords': array([ 3.3115 , 21.11625,  9.444  ]), 'type': 'DV'} 1\n",
      "92 {'fcoords': array([ 1.  ,  1.25, -0.25]), 'ccoords': array([ 6.623  , 21.11625, -3.148  ]), 'type': 'DV'} 1\n",
      "0 {'fcoords': array([0.  , 0.25, 0.75]), 'ccoords': array([0.     , 4.22325, 9.444  ]), 'type': 'V'} 2\n",
      "53 {'fcoords': array([ 0.  , -0.25,  1.25]), 'ccoords': array([ 0.     , -4.22325, 15.74   ]), 'type': 'DV'} 1\n",
      "37 {'fcoords': array([0.  , 0.75, 1.25]), 'ccoords': array([ 0.     , 12.66975, 15.74   ]), 'type': 'DV'} 1\n",
      "4 {'fcoords': array([1.  , 0.25, 0.75]), 'ccoords': array([6.623  , 4.22325, 9.444  ]), 'type': 'DV'} 2\n",
      "61 {'fcoords': array([ 1.  , -0.25,  1.25]), 'ccoords': array([ 6.623  , -4.22325, 15.74   ]), 'type': 'DV'} 1\n",
      "41 {'fcoords': array([1.  , 0.75, 1.25]), 'ccoords': array([ 6.623  , 12.66975, 15.74   ]), 'type': 'DV'} 1\n",
      "(1, 72) {'fcoords': (array([0.  , 0.75, 0.25]), array([ 0.  ,  0.25, -0.25])), 'fc_center': array([0. , 0.5, 0. ]), 'type': 'E'}\n",
      "(1, 84) {'fcoords': (array([0.  , 0.75, 0.25]), array([ 0.  ,  1.25, -0.25])), 'fc_center': array([0., 1., 0.]), 'type': 'DE'}\n",
      "(2, 19) {'fcoords': (array([0.5 , 0.25, 0.75]), array([ 0.5 , -0.25,  0.25])), 'fc_center': array([0.5, 0. , 0.5]), 'type': 'E'}\n",
      "(2, 3) {'fcoords': (array([0.5 , 0.25, 0.75]), array([0.5 , 0.75, 0.25])), 'fc_center': array([0.5, 0.5, 0.5]), 'type': 'E'}\n",
      "(3, 14) {'fcoords': (array([0.5 , 0.75, 0.25]), array([0.5 , 1.25, 0.75])), 'fc_center': array([0.5, 1. , 0.5]), 'type': 'DE'}\n",
      "(5, 76) {'fcoords': (array([1.  , 0.75, 0.25]), array([ 1.  ,  0.25, -0.25])), 'fc_center': array([1. , 0.5, 0. ]), 'type': 'DE'}\n",
      "(5, 92) {'fcoords': (array([1.  , 0.75, 0.25]), array([ 1.  ,  1.25, -0.25])), 'fc_center': array([1., 1., 0.]), 'type': 'DE'}\n",
      "(0, 53) {'fcoords': (array([0.  , 0.25, 0.75]), array([ 0.  , -0.25,  1.25])), 'fc_center': array([0., 0., 1.]), 'type': 'DE'}\n",
      "(0, 37) {'fcoords': (array([0.  , 0.25, 0.75]), array([0.  , 0.75, 1.25])), 'fc_center': array([0. , 0.5, 1. ]), 'type': 'DE'}\n",
      "(4, 61) {'fcoords': (array([1.  , 0.25, 0.75]), array([ 1.  , -0.25,  1.25])), 'fc_center': array([1., 0., 1.]), 'type': 'DE'}\n",
      "(4, 41) {'fcoords': (array([1.  , 0.25, 0.75]), array([1.  , 0.75, 1.25])), 'fc_center': array([1. , 0.5, 1. ]), 'type': 'DE'}\n"
     ]
    }
   ],
   "source": [
    "#check connectivity of each node in G\n",
    "def check_connectivity(G):\n",
    "    for n in G.nodes():\n",
    "        print(n,G.nodes[n],G.degree(n))\n",
    "check_connectivity(G)\n",
    "\n",
    "#check edge information in G\n",
    "def check_edge(G):\n",
    "    for e in G.edges():\n",
    "        print(e,G.edges[e])\n",
    "check_edge(G)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#firstly, check if all V nodes have highest connectivity\n",
    "#secondly, sort all DV nodes by connectivity\n",
    "def sort_nodes_by_type_connectivity(G):\n",
    "    Vnodes = [n for n in G.nodes() if G.nodes[n]['type']=='V']\n",
    "    DVnodes = [n for n in G.nodes() if G.nodes[n]['type']=='DV']\n",
    "    Vnodes = sorted(Vnodes,key=lambda x: G.degree(x),reverse=True)\n",
    "    DVnodes = sorted(DVnodes,key=lambda x: G.degree(x),reverse=True)\n",
    "    return Vnodes+DVnodes\n",
    "sorted_nodes = sort_nodes_by_type_connectivity(G)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fix one direction of the box, which should be parallel to the pilalar direction\n",
    "\n",
    "#rotate the node to pillar direction and put all nodes into the cartesian coordinate \n",
    "def check_edge_inunitcell(e):\n",
    "    if 'DV' in G.nodes[e[0]]['type'] or 'DV' in G.nodes[e[1]]['type']:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def find_and_sort_edges_bynodeconnectivity(graph, sorted_nodes):\n",
    "    all_edges = list(graph.edges())\n",
    "\n",
    "    sorted_edges = []\n",
    "    #add unit_cell edge first\n",
    "\n",
    "    ei = 0\n",
    "    while ei < len(all_edges):\n",
    "            e = all_edges[ei]\n",
    "            if check_edge_inunitcell(e):\n",
    "                sorted_edges.append(e)\n",
    "                all_edges.pop(ei)\n",
    "            ei += 1\n",
    "    #sort edge by sorted_nodes\n",
    "    for n in sorted_nodes:\n",
    "        ei = 0\n",
    "        while ei < len(all_edges):\n",
    "            e = all_edges[ei]\n",
    "            if n in e:\n",
    "                if n ==e[0]:\n",
    "                    sorted_edges.append(e)\n",
    "                else:\n",
    "                    sorted_edges.append((int(e[1]),int(e[0])))\n",
    "                all_edges.pop(ei)\n",
    "            else:\n",
    "                ei += 1\n",
    "\n",
    "    return sorted_edges    \n",
    "    \n",
    "sorted_edges = find_and_sort_edges_bynodeconnectivity(G,sorted_nodes)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#debug\n",
    "###save the sorted nodes ccoords as xyz\n",
    "##def save_node_xyz(sorted_nodes,unit_cell,G):\n",
    "##    with open('sorted_nodes.xyz','w') as f:\n",
    "##        f.write(str(len(sorted_nodes))+'\\n')\n",
    "##        f.write('sorted_nodes\\n')\n",
    "##        for n in sorted_nodes:\n",
    "##            ccoords = np.dot(unit_cell,G.nodes[n]['fcoords']).tolist()\n",
    "##            f.write('V'+str(sorted_nodes.index(n))+'    '+' '.join(map(str,ccoords))+'\\n')\n",
    "##save_node_xyz(sorted_nodes,unit_cell,G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pillar stack [1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "#loop node in G, for each node, find the nearest node, and calculte the node_node vector, check if all of the pair vector are parallel\n",
    "from numpy.linalg import norm\n",
    "def check_if_pillarstack(G):\n",
    "    node_node_vec = []\n",
    "    for n in G.nodes():\n",
    "        if 'DV' in G.nodes[n]['type']:\n",
    "            continue\n",
    "        dist = []\n",
    "        for nn in G.nodes():\n",
    "            dist.append(np.linalg.norm(G.nodes[n]['fcoords']-G.nodes[nn]['fcoords']))\n",
    "        dist = np.array(dist)\n",
    "        if np.min(dist) < 1e-3:\n",
    "            dist[np.argmin(dist)] = 1000\n",
    "        if np.min(dist) > 1:\n",
    "            continue\n",
    "\n",
    "        nn = list(G.nodes())[np.argmin(dist)]\n",
    "        node_node = G.nodes[n]['fcoords']-G.nodes[nn]['fcoords']\n",
    "        node_node = node_node/norm(node_node)\n",
    "        node_node_vec.append(node_node)\n",
    "        \n",
    "    #check if all of the pair vector are parallel\n",
    "    for i in range(0,len(node_node_vec)):\n",
    "        for j in range(i+1,len(node_node_vec)):\n",
    "            if norm(np.cross(node_node_vec[i],node_node_vec[j])) > 1e-3:\n",
    "                print('not pillar stack')\n",
    "                return False,None\n",
    "    pillar_vec = np.abs(node_node_vec[0])\n",
    "    print('pillar stack',pillar_vec)\n",
    "    return True,pillar_vec\n",
    "\n",
    "\n",
    "PILLAR,pillar_vec = check_if_pillarstack(G)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "beginning_point = [0.0,0.0,0.0]\n",
    "rms,rot,tran = superimpose([beginning_point,node_pillar_cvec],[beginning_point,pillar_vec])\n",
    "pillar_oriented_nodexvec=np.dot(np.asarray(node_x_vecs),rot)\n",
    "pillar_oriented_node_xcoords = np.dot(unit_cell,pillar_oriented_nodexvec.T).T\n",
    "pillar_oriented_node_fcoords = np.dot(chain_node_fcoords,rot)\n",
    "pillar_oriented_node_coords = np.dot(unit_cell,pillar_oriented_node_fcoords.T).T\n",
    "nodexxxx = []\n",
    "xxxx_positions_dict = {}\n",
    "chain_node_positions_dict = {}\n",
    "chain_node_positions = []\n",
    "#for n in sorted_nodes:\n",
    "#    nodexxxx.append(G.nodes[n]['ccoords']+pillar_oriented_nodexvec)\n",
    "#    chain_node_positions.append(G.nodes[n]['ccoords']+pillar_oriented_nodecoords)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add row indices as the first column\n",
    "def addidx(array):\n",
    "    row_indices = np.arange(array.shape[0]).reshape(-1, 1).astype(int)\n",
    "\n",
    "    new_array = np.hstack((row_indices, array))\n",
    "    return new_array\n",
    "\n",
    "#reindex the nodes in the xxxx_positions with the index in the sorted_nodes, like G has 16 nodes[2,5,7], but the new dictionary should be [0,1,2]\n",
    "xxxx_positions_dict = {sorted_nodes.index(n):addidx(G.nodes[n]['ccoords']+pillar_oriented_node_xcoords) for n in sorted_nodes}\n",
    "chain_node_positions_dict = {sorted_nodes.index(n):G.nodes[n]['ccoords']+pillar_oriented_node_coords for n in sorted_nodes}\n",
    "#reindex the edges in the G with the index in the sorted_nodes\n",
    "sorted_edges = [(sorted_nodes.index(e[0]),sorted_nodes.index(e[1])) for e in sorted_edges]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0,\n",
       " 16,\n",
       " NodeView((1, 72, 2, 19, 3, 5, 76, 84, 14, 92, 0, 53, 37, 4, 61, 41)),\n",
       " [(1, 2),\n",
       "  (0, 6),\n",
       "  (0, 9),\n",
       "  (1, 7),\n",
       "  (2, 10),\n",
       "  (3, 12),\n",
       "  (3, 13),\n",
       "  (4, 8),\n",
       "  (4, 11),\n",
       "  (5, 14),\n",
       "  (5, 15)])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nodexxxx),G.number_of_nodes(),G.nodes(),sorted_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0), (1, 1)]\n",
      "[(0, 0), (1, 1)]\n",
      "[(0, 0)]\n",
      "[(0, 1)]\n",
      "[(0, 0)]\n",
      "[(0, 0), (1, 1)]\n",
      "[(0, 0)]\n",
      "[(0, 0), (1, 1)]\n",
      "[(0, 0)]\n",
      "[(0, 0), (1, 1)]\n",
      "[(0, 0)]\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =           16     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.51399D+03    |proj g|=  6.77230D+01\n",
      "\n",
      "At iterate    1    f=  1.38192D+03    |proj g|=  4.86643D+01\n",
      "\n",
      "At iterate    2    f=  1.24750D+03    |proj g|=  3.00794D+01\n",
      "\n",
      "At iterate    3    f=  1.21359D+03    |proj g|=  1.27907D+01\n",
      "\n",
      "At iterate    4    f=  1.20590D+03    |proj g|=  1.18758D+01\n",
      "\n",
      "At iterate    5    f=  1.19990D+03    |proj g|=  7.86717D+00\n",
      "\n",
      "At iterate    6    f=  1.19723D+03    |proj g|=  5.26691D+00\n",
      "\n",
      "At iterate    7    f=  1.19502D+03    |proj g|=  4.85966D+00\n",
      "\n",
      "At iterate    8    f=  1.17485D+03    |proj g|=  2.87587D+01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "At iterate    9    f=  1.17320D+03    |proj g|=  3.10304D+01\n",
      "\n",
      "At iterate   10    f=  1.15801D+03    |proj g|=  3.31398D+01\n",
      "\n",
      "At iterate   11    f=  1.13528D+03    |proj g|=  1.41585D+01\n",
      "\n",
      "At iterate   12    f=  1.13015D+03    |proj g|=  9.43376D+00\n",
      "\n",
      "At iterate   13    f=  1.12862D+03    |proj g|=  2.92584D+00\n",
      "\n",
      "At iterate   14    f=  1.12844D+03    |proj g|=  2.09513D+00\n",
      "\n",
      "At iterate   15    f=  1.12835D+03    |proj g|=  8.75411D-01\n",
      "\n",
      "At iterate   16    f=  1.12833D+03    |proj g|=  1.85855D-01\n",
      "\n",
      "At iterate   17    f=  1.12833D+03    |proj g|=  3.18096D-02\n",
      "Optimized Pairings (after optimization):\n",
      "Node 1 and Node 2:\n",
      "  node1_0 -- node2_0\n",
      "  node1_1 -- node2_1\n",
      "Node 0 and Node 6:\n",
      "  node0_0 -- node6_0\n",
      "  node0_1 -- node6_1\n",
      "Node 0 and Node 9:\n",
      "  node0_1 -- node9_0\n",
      "Node 1 and Node 7:\n",
      "  node1_1 -- node7_1\n",
      "Node 2 and Node 10:\n",
      "  node2_1 -- node10_0\n",
      "Node 3 and Node 12:\n",
      "  node3_0 -- node12_0\n",
      "  node3_1 -- node12_1\n",
      "Node 3 and Node 13:\n",
      "  node3_1 -- node13_0\n",
      "Node 4 and Node 8:\n",
      "  node4_0 -- node8_0\n",
      "  node4_1 -- node8_1\n",
      "Node 4 and Node 11:\n",
      "  node4_1 -- node11_0\n",
      "Node 5 and Node 14:\n",
      "  node5_0 -- node14_0\n",
      "  node5_1 -- node14_1\n",
      "Node 5 and Node 15:\n",
      "  node5_1 -- node15_0\n",
      "\n",
      "\n",
      "At iterate   18    f=  1.12833D+03    |proj g|=  1.24146D-02\n",
      "\n",
      "At iterate   19    f=  1.12833D+03    |proj g|=  4.09273D-03\n",
      "\n",
      "At iterate   20    f=  1.12833D+03    |proj g|=  5.22959D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "   16     20     25      1     0     0   5.230D-04   1.128D+03\n",
      "  F =   1128.3302174558107     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize, linear_sum_assignment\n",
    "import networkx as nx\n",
    "\n",
    "\n",
    "def reorthogonalize_matrix(matrix):\n",
    "    \"\"\"\n",
    "    Ensure the matrix is a valid rotation matrix with determinant = 1.\n",
    "    \"\"\"\n",
    "    U, _, Vt = np.linalg.svd(matrix)\n",
    "    R = np.dot(U, Vt)\n",
    "    if np.linalg.det(R) < 0:\n",
    "        U[:, -1] *= -1\n",
    "        R = np.dot(U, Vt)\n",
    "    return R\n",
    "\n",
    "def find_optimal_pairings(node_i_positions, node_j_positions):\n",
    "    \"\"\"\n",
    "    Find the optimal one-to-one pairing between atoms in two nodes using the Hungarian algorithm.\n",
    "    \"\"\"\n",
    "    num_i, num_j = len(node_i_positions), len(node_j_positions)\n",
    "    cost_matrix = np.zeros((num_i, num_j))\n",
    "    for i in range(num_i):\n",
    "        for j in range(num_j):\n",
    "            cost_matrix[i, j] = np.linalg.norm(node_i_positions[i,1:] - node_j_positions[j,1:])\n",
    "\n",
    "    row_ind, col_ind = linear_sum_assignment(cost_matrix)\n",
    "\n",
    "    print(list(zip(row_ind, col_ind)))\n",
    "    return list(zip(row_ind, col_ind))\n",
    "\n",
    "#pairing the atoms in two nodes, but with NOSYMNO as TRUE, \n",
    "# pairs of actual index are limit to [0,0],[1,1]...,the index is stored in the first column \n",
    "# of the atom_positions,we need to compare the distance between index pairs in both nodes, to find the optimal pairings\n",
    "# the optimal pairings should have the minimum distance between the pair of atoms in two nodes\n",
    "# the optimal pairings should be the same as the pair of index in the atom_positions\n",
    "def find_nosymno_optimal_pairings(node_i_positions, node_j_positions,static_node_i_positions,static_node_j_positions):\n",
    "    #find the optimal pair with same index in both nodes\n",
    "    #index is stored in the first column of the atom_positions\n",
    "    indices_of_node_i = node_i_positions[:,0]\n",
    "    indices_of_node_j = node_j_positions[:,0]\n",
    "    #find overlap index\n",
    "    overlap_indices = np.intersect1d(indices_of_node_i, indices_of_node_j)\n",
    "    #find the shortest distance between the overlap index\n",
    "    distances = []\n",
    "    for idx in overlap_indices:\n",
    "        i = np.where(indices_of_node_i == idx)[0][0]\n",
    "        j = np.where(indices_of_node_j == idx)[0][0]\n",
    "        distances.append(np.linalg.norm(node_i_positions[i,1:] - node_j_positions[j,1:]))\n",
    "    #find the index of the shortest distance\n",
    "    sorted_indices = np.argsort(distances)\n",
    "    \n",
    "    #if more than one shortest distance, return the one in node_i who is closer to the middle point of mass center of node_ and node_j\n",
    "    #if shorstest distance is more than one, find the center of mass of the overlap index, and find the distance between the center of mass and the overlap index\n",
    "    #if the distance is larger, then switch the order of the index\n",
    "    if len(sorted_indices)>1 :\n",
    "        if (distances[sorted_indices[0]]-distances[sorted_indices[1]] < 1e-3):\n",
    "            com_i = np.mean(static_node_i_positions[:,1:], axis=0)\n",
    "            com_j = np.mean(static_node_j_positions[:,1:], axis=0)\n",
    "            middle = (com_i + com_j) / 2\n",
    "            def distance_to_middle(middle,idx_in_node_i):\n",
    "                position_in_node_i = node_i_positions[np.where(indices_of_node_i == idx_in_node_i)[0][0],1:]\n",
    "                return np.linalg.norm(middle - position_in_node_i)\n",
    "            #if this egde is E type, i,j nodes are V type node: #this edge is inside,we should make the beginning towards inside \n",
    "            if distance_to_middle(middle,overlap_indices[sorted_indices[0]]) - distance_to_middle(middle,overlap_indices[sorted_indices[1]]) >1e-3:\n",
    "                #switch the order of first and second index, others are the same\n",
    "                new_sorted_indices = [sorted_indices[1],sorted_indices[0]]+list(sorted_indices[2:])\n",
    "                sorted_ovelap_indices = [overlap_indices[idx] for idx in new_sorted_indices]\n",
    "                return list(zip(np.where(indices_of_node_i == sorted_ovelap_indices[0])[0],np.where(indices_of_node_j == sorted_ovelap_indices[0])[0]))\n",
    "            ##if this egde is DE type, one of i,j nodes are DV type node: #this edge is outside, we should make the beginning towards outside\n",
    "            ##    if distance_to_middle(middle,overlap_indices[sorted_indices[0]]) - distance_to_middle(middle,overlap_indices[sorted_indices[1]]) >1e-3:\n",
    "            ##        #switch the order of first and second index, others are the same\n",
    "            ##        new_sorted_indices = [sorted_indices[1],sorted_indices[0]]+list(sorted_indices[2:])\n",
    "            ##        sorted_ovelap_indices = [overlap_indices[idx] for idx in new_sorted_indices]\n",
    "            ##        return list(zip(np.where(indices_of_node_i == sorted_ovelap_indices[0])[0],np.where(indices_of_node_j == sorted_ovelap_indices[0])[0]))\n",
    "\n",
    "    #find the pairs of the overlap index, sort index by the distance, and return list(zip(overlap_indices,overlap_indices))\n",
    "    #return a list zip of the index of the overlap index row index in node_i_positions and node_j_positions,  which is the optimal pair, order is the distance between opverlap index\n",
    "    sorted_ovelap_indices = [overlap_indices[idx] for idx in sorted_indices]\n",
    "    return list(zip(np.where(indices_of_node_i == sorted_ovelap_indices[0])[0],np.where(indices_of_node_j == sorted_ovelap_indices[0])[0]))\n",
    "\n",
    "def update_pairs(pairs,atom_positions,i,j):\n",
    "    nodeA_idx_set = atom_positions[i][:,0]\n",
    "    nodeB_idx_set = atom_positions[j][:,0]\n",
    "    correct_idx_pair =[]\n",
    "    for k in range(len(pairs)):\n",
    "        idx_A,idx_B = nodeA_idx_set[pairs[k][0]],nodeB_idx_set[pairs[k][1]]\n",
    "        correct_idx_pair.append((idx_A,idx_B))\n",
    "    return correct_idx_pair\n",
    "\n",
    "def find_edge_pairings(sorted_edges, atom_positions,static_atom_positions):\n",
    "    \"\"\"\n",
    "    Identify optimal pairings for each edge in the graph.\n",
    "\n",
    "    Parameters:\n",
    "        G (networkx.Graph): Graph structure with edges between nodes.\n",
    "        atom_positions (dict): Positions of X atoms for each node.\n",
    "\n",
    "    Returns:\n",
    "        dict: Mapping of edges to optimal atom pairs.\n",
    "              Example: {(0, 1): [(0, 3), (1, 2)], ...}\n",
    "    \"\"\"\n",
    "\n",
    "    edge_pairings = {}\n",
    "    \n",
    "    for i, j in sorted_edges:\n",
    "        node_i_positions = atom_positions[i] #[index,x,y,z]\n",
    "        node_j_positions = atom_positions[j] #[index,x,y,z]\n",
    "        static_node_i_positions = static_atom_positions[i] #[index,x,y,z]\n",
    "        static_node_j_positions = static_atom_positions[j] #[index,x,y,z]\n",
    "\n",
    "        # Find optimal pairings for this edge\n",
    "        #pairs = find_nosymno_optimal_pairings(node_i_positions, node_j_positions,static_node_i_positions,static_node_j_positions)\n",
    "        pairs = find_optimal_pairings(node_i_positions, node_j_positions)\n",
    "        idx_0,idx_1 = pairs[0]\n",
    "       ##if i==1 and j==2: #TODO: TEST DEBUG\n",
    "       ##    idx_0 = 1\n",
    "       ##    idx_1 = 1\n",
    "       ##    edge_pairings[(i, j)] = [(1,1)]\n",
    "       ##    atom_positions[i] = np.delete(atom_positions[i], idx_0, axis=0)\n",
    "       ##    atom_positions[j] = np.delete(atom_positions[j], idx_1, axis=0)\n",
    "       ##    continue\n",
    "        #if i==2 and j==1: #TODO: TEST DEBUG\n",
    "        #    idx_0 = 1\n",
    "        #    idx_1 = 1\n",
    "        #    edge_pairings[(i, j)] = [(1,1)]\n",
    "        #    atom_positions[i] = np.delete(atom_positions[i], idx_0, axis=0)\n",
    "        #    atom_positions[j] = np.delete(atom_positions[j], idx_1, axis=0)\n",
    "        #    continue\n",
    "        x_idx_0 = atom_positions[i][idx_0][0]\n",
    "        x_idx_1 = atom_positions[j][idx_1][0]\n",
    " \n",
    "        edge_pairings[(i, j)] = update_pairs(pairs,atom_positions,i,j) #but only first pair match\n",
    "        atom_positions[i] = np.delete(atom_positions[i], idx_0, axis=0)\n",
    "        atom_positions[j] = np.delete(atom_positions[j], idx_1, axis=0)\n",
    "\n",
    "    return edge_pairings\n",
    "\n",
    "\n",
    "def axis_rotation_matrix(axis, theta):\n",
    "    \"\"\"\n",
    "    Compute the rotation matrix for a rotation around an axis by an angle theta.\n",
    "\n",
    "    Parameters:\n",
    "        axis (tuple): The axis vector (a, b, c).\n",
    "        theta (float): The rotation angle in radians.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: The 3x3 rotation matrix.\n",
    "    \"\"\"\n",
    "    a, b, c = axis\n",
    "    axis = np.array([a, b, c])\n",
    "    axis = axis / np.linalg.norm(axis)  # Normalize the axis vector\n",
    "    a, b, c = axis\n",
    "\n",
    "    cos_theta = np.cos(theta)\n",
    "    sin_theta = np.sin(theta)\n",
    "    I = np.eye(3)\n",
    "    K = np.array([\n",
    "        [0, -c, b],\n",
    "        [c, 0, -a],\n",
    "        [-b, a, 0]\n",
    "    ])\n",
    "    \n",
    "    R = I + sin_theta * K + (1 - cos_theta) * np.dot(K, K)\n",
    "    return R\n",
    "\n",
    "def axis_objective_function(thetas, axis, static_atom_positions, edge_pairings):\n",
    "    \"\"\"\n",
    "    Objective function to minimize distances between paired atoms along edges.\n",
    "\n",
    "    Parameters:\n",
    "        theta (float): The rotation angle in radians.\n",
    "        axis (tuple): The axis vector (a, b, c).\n",
    "        G (networkx.Graph): Graph structure.\n",
    "        static_atom_positions (dict): Original positions of X atoms for each node.\n",
    "        edge_pairings (dict): Precomputed pairings for each edge.\n",
    "\n",
    "    Returns:\n",
    "        float: Total distance metric to minimize.\n",
    "    \"\"\"\n",
    "    total_distance = 0.0\n",
    "\n",
    "    for (i, j), pairs in edge_pairings.items():\n",
    "        R_i = reorthogonalize_matrix(axis_rotation_matrix(axis, thetas[i]))\n",
    "        R_j = reorthogonalize_matrix(axis_rotation_matrix(axis, thetas[j]))\n",
    "\n",
    "        com_i = G.nodes[sorted_nodes[i]]['ccoords']\n",
    "        com_j = G.nodes[sorted_nodes[j]]['ccoords']\n",
    "\n",
    "        # Rotate positions around their mass center\n",
    "        rotated_i_positions = np.dot(static_atom_positions[i][:,1:] - com_i, R_i.T) + com_i\n",
    "        rotated_j_positions = np.dot(static_atom_positions[j][:,1:] - com_j, R_j.T) + com_j\n",
    "\n",
    "        for idx_i, idx_j in pairs:\n",
    "            dist = np.linalg.norm(rotated_i_positions[int(idx_i)] - rotated_j_positions[int(idx_j)])\n",
    "            total_distance += dist ** 2\n",
    "\n",
    "    return total_distance\n",
    "\n",
    "\n",
    "def axis_optimize_rotations(axis, num_nodes,sorted_edges, atom_positions):\n",
    "    \"\"\"\n",
    "    Optimize the rotation angles around a given axis to minimize the difference between\n",
    "    rotated and target positions for each node.\n",
    "\n",
    "    Parameters:\n",
    "        axis (tuple): The axis vector (a, b, c).\n",
    "        G (networkx.Graph): Graph structure.\n",
    "        static_atom_positions (dict): Original positions of X atoms for each node.\n",
    "        edge_pairings (dict): Precomputed pairings for each edge.\n",
    "        initial_thetas (numpy.ndarray): Initial guesses for the rotation angles.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: The optimized rotation angles for each node.\n",
    "    \"\"\"\n",
    "    initial_thetas = np.zeros(num_nodes) # Initial guess for rotation angles\n",
    "    static_atom_positions = atom_positions.copy()\n",
    "    # Precompute edge-specific pairings\n",
    "    edge_pairings = find_edge_pairings(sorted_edges, atom_positions,static_atom_positions)\n",
    "    result = minimize(axis_objective_function, initial_thetas, \n",
    "                      args=(axis,  static_atom_positions, edge_pairings), \n",
    "                      method='L-BFGS-B',options={\"maxiter\": 5000, \"disp\": True})\n",
    "    optimized_thetas = result.x\n",
    "\n",
    "    # Compute the rotation matrices for each node\n",
    "    optimized_rotations = [reorthogonalize_matrix(axis_rotation_matrix(axis, theta)) for theta in optimized_thetas]\n",
    "    \n",
    "    # Print the optimized pairings after optimization\n",
    "    print(\"Optimized Pairings (after optimization):\")\n",
    "    for (i, j), pairs in edge_pairings.items():\n",
    "        print(f\"Node {i} and Node {j}:\")\n",
    "        for idx_i, idx_j in pairs:\n",
    "            print(f\"  node{i}_{int(idx_i)} -- node{j}_{int(idx_j)}\")\n",
    "    print()\n",
    "\n",
    "    return optimized_rotations\n",
    "\n",
    "def compute_rotation_with_pairing(connected_nodes, atom_positions,current_rotation_matrix):\n",
    "    \"\"\"\n",
    "    Compute the optimal rotation matrix for node pairs, starting from the current rotation matrix.\n",
    "    \n",
    "    Parameters:\n",
    "        node_i_positions (numpy.ndarray): Positions of X atoms in node i (Nx3 array).\n",
    "        node_j_positions (numpy.ndarray): Positions of X atoms in node j (Mx3 array).\n",
    "        current_rotation_matrix (numpy.ndarray): The current 3x3 rotation matrix for node i.\n",
    "\n",
    "    Returns:\n",
    "        rotation_matrix (numpy.ndarray): Optimized 3x3 rotation matrix for node i.\n",
    "    \"\"\"\n",
    "    \n",
    "    i, j = connected_nodes\n",
    "    # Extract paired positions\n",
    "    paired_node_i = atom_positions[i][:,1:]\n",
    "    paired_node_j = atom_positions[j][:,1:]\n",
    "\n",
    "    # Compute the centers of mass for both sets\n",
    "    com_i = np.mean(paired_node_i, axis=0)\n",
    "    com_j = np.mean(paired_node_j, axis=0)\n",
    "\n",
    "    # Translate positions to the center of mass\n",
    "    translated_i = paired_node_i - com_i\n",
    "    translated_j = paired_node_j - com_j\n",
    "\n",
    "    # Apply the current rotation matrix to node_i's positions\n",
    "    rotated_translated_i = np.dot(translated_i, current_rotation_matrix.T)\n",
    "\n",
    "    # Compute covariance matrix and SVD\n",
    "    H = np.dot(rotated_translated_i.T, translated_j)\n",
    "    U, _, Vt = np.linalg.svd(H)\n",
    "    R = np.dot(U, Vt)\n",
    "\n",
    "    # Ensure the resulting matrix is a valid rotation matrix (det = 1)\n",
    "    if np.linalg.det(R) < 0:\n",
    "        U[:, -1] *= -1\n",
    "        R = np.dot(U, Vt)\n",
    "\n",
    "    # Update the rotation matrix by combining the current and incremental rotation\n",
    "    optimized_rotation_matrix = np.dot(R, current_rotation_matrix)\n",
    "\n",
    "    return optimized_rotation_matrix\n",
    "\n",
    "def objective_function(params, G, static_atom_positions, edge_pairings):\n",
    "    \"\"\"\n",
    "    Objective function to minimize distances between paired atoms along edges.\n",
    "\n",
    "    Parameters:\n",
    "        params (numpy.ndarray): Flattened array of rotation matrices.\n",
    "        G (networkx.Graph): Graph structure.\n",
    "        atom_positions (dict): Original positions of X atoms for each node.\n",
    "        edge_pairings (dict): Precomputed pairings for each edge.\n",
    "\n",
    "    Returns:\n",
    "        float: Total distance metric to minimize.\n",
    "    \"\"\"\n",
    "    num_nodes = len(G.nodes())\n",
    "    rotation_matrices = params.reshape(num_nodes, 3, 3)\n",
    "    total_distance = 0.0\n",
    "\n",
    "    for (i, j), pairs in edge_pairings.items():\n",
    "        R_i = reorthogonalize_matrix(rotation_matrices[i])\n",
    "        R_j = reorthogonalize_matrix(rotation_matrices[j])\n",
    "\n",
    "        com_i = G.nodes[sorted_nodes[i]]['ccoords']\n",
    "        com_j = G.nodes[sorted_nodes[j]]['ccoords']\n",
    "\n",
    "        # Rotate positions around their mass center\n",
    "        rotated_i_positions = np.dot(static_atom_positions[i][:,1:] - com_i, R_i.T) + com_i\n",
    "        rotated_j_positions = np.dot(static_atom_positions[j][:,1:] - com_j, R_j.T) + com_j\n",
    "\n",
    "\n",
    "        for idx_i, idx_j in pairs:\n",
    "            dist = np.linalg.norm(rotated_i_positions[int(idx_i)] - rotated_j_positions[int(idx_j)])\n",
    "            total_distance += dist ** 2\n",
    "\n",
    "    return total_distance\n",
    "\n",
    "\n",
    "def optimize_rotations(num_nodes, sorted_edges,atom_positions):\n",
    "    \"\"\"\n",
    "    Optimize rotations for all nodes in the graph.\n",
    "\n",
    "    Parameters:\n",
    "        G (networkx.Graph): Graph structure with edges between nodes.\n",
    "        atom_positions (dict): Positions of X atoms for each node.\n",
    "\n",
    "    Returns:\n",
    "        list: Optimized rotation matrices for all nodes.\n",
    "    \"\"\"\n",
    "    initial_rotations = np.tile(np.eye(3), (num_nodes, 1)).flatten()\n",
    "    static_atom_positions = atom_positions.copy()\n",
    "    # Precompute edge-specific pairings\n",
    "    edge_pairings = find_edge_pairings(sorted_edges, atom_positions,static_atom_positions)\n",
    "\n",
    "    result = minimize(\n",
    "        objective_function,\n",
    "        initial_rotations,\n",
    "        args=(G, static_atom_positions, edge_pairings),\n",
    "        method=\"L-BFGS-B\",\n",
    "        options={\"maxiter\": 5000, \"disp\": True, 'ftol': 1e-9,  # Smaller tolerance on function value\n",
    "                'gtol': 1e-5,  # Smaller gradient tolerance\n",
    "                'maxfun': 10000 } # Higher max evaluations\n",
    "    )\n",
    "\n",
    "    \n",
    "\n",
    "    optimized_rotations = result.x.reshape(num_nodes, 3, 3)\n",
    "    optimized_rotations = [reorthogonalize_matrix(R) for R in optimized_rotations]\n",
    "    \n",
    "    # Print the optimized pairings after optimization\n",
    "    print(\"Optimized Pairings (after optimization):\")\n",
    "    for (i, j), pairs in edge_pairings.items():\n",
    "        print(f\"Node {i} and Node {j}:\")\n",
    "        for idx_i, idx_j in pairs:\n",
    "            print(f\"  node{i}_{idx_i} -- node{j}_{idx_j}\")\n",
    "    print()\n",
    "\n",
    "    return optimized_rotations,static_atom_positions\n",
    "\n",
    "def apply_rotations_to_atom_positions(optimized_rotations, G, atom_positions):\n",
    "    \"\"\"\n",
    "    Apply the optimized rotation matrices to the atom positions.\n",
    "\n",
    "    Parameters:\n",
    "        optimized_rotations (list): Optimized rotation matrices for each node.\n",
    "        G (networkx.Graph): Graph structure.\n",
    "        atom_positions (dict): Original positions of X atoms for each node.\n",
    "\n",
    "    Returns:\n",
    "        dict: Rotated positions for each node.\n",
    "    \"\"\"\n",
    "    rotated_positions = {}\n",
    "\n",
    "    for i, node in enumerate(sorted_nodes):\n",
    "        #if node type is V\n",
    "        #if 'DV' in G.nodes[node]['type']:\n",
    "          #  continue\n",
    "        R = optimized_rotations[i]\n",
    "        original_positions = atom_positions[i]\n",
    "        com = G.nodes[node]['ccoords']\n",
    "\n",
    "        # Translate, rotate, and translate back to preserve the mass center\n",
    "        translated_positions = original_positions - com\n",
    "        rotated_translated_positions = np.dot(translated_positions, R.T)\n",
    "        rotated_positions[node] = rotated_translated_positions + com\n",
    "\n",
    "    return rotated_positions\n",
    "\n",
    "def save_xyz(filename, rotated_positions):\n",
    "    \"\"\"\n",
    "    Save the rotated positions to an XYZ file for visualization.\n",
    "    \"\"\"\n",
    "    with open(filename, \"w\") as file:\n",
    "        num_atoms = sum(len(positions) for positions in rotated_positions.values())\n",
    "        file.write(f\"{num_atoms}\\n\")\n",
    "        file.write(\"Optimized structure\\n\")\n",
    "\n",
    "        for node, positions in rotated_positions.items():\n",
    "            for pos in positions:\n",
    "                file.write(f\"X{node}   {pos[0]:.8f} {pos[1]:.8f} {pos[2]:.8f}\\n\")\n",
    "\n",
    "\n",
    "\n",
    "# Optimize rotations\n",
    "num_nodes = G.number_of_nodes()\n",
    "\n",
    "###3D free rotation\n",
    "#optimized_rotations,static_xxxx_positions = optimize_rotations(num_nodes,sorted_edges, xxxx_positions_dict)\n",
    "\n",
    "\n",
    "###2D axis rotation\n",
    "axis = pillar_vec  # Rotate around x-axis\n",
    "optimized_rotations = axis_optimize_rotations(axis, num_nodes, sorted_edges, xxxx_positions_dict)\n",
    "\n",
    "\n",
    "\n",
    "# Apply rotations\n",
    "rotated_positions = apply_rotations_to_atom_positions(optimized_rotations, G, chain_node_positions_dict)\n",
    "\n",
    "# Save results to XYZ\n",
    "save_xyz(\"optimized_xxxxstructure.xyz\", rotated_positions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'a' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[51], line 51\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39msum(np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mnorm(fractional_coords_new \u001b[38;5;241m-\u001b[39m old_fractional_coords, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# Old cell parameters (example values)\u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m old_cell_params \u001b[38;5;241m=\u001b[39m [\u001b[43ma\u001b[49m, b, c, ang_alpha, ang_beta, ang_gamma]  \u001b[38;5;66;03m# [a, b, c, alpha, beta, gamma]\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# Old Cartesian coordinates of points (example values)\u001b[39;00m\n\u001b[1;32m     54\u001b[0m old_cartesian_coords \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\n\u001b[1;32m     55\u001b[0m     [\u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m0.0\u001b[39m],    \u001b[38;5;66;03m# Point 1\u001b[39;00m\n\u001b[1;32m     56\u001b[0m     [\u001b[38;5;241m2.5\u001b[39m, \u001b[38;5;241m3.0\u001b[39m, \u001b[38;5;241m3.5\u001b[39m],    \u001b[38;5;66;03m# Point 2\u001b[39;00m\n\u001b[1;32m     57\u001b[0m     [\u001b[38;5;241m1.25\u001b[39m, \u001b[38;5;241m1.5\u001b[39m, \u001b[38;5;241m5.25\u001b[39m],  \u001b[38;5;66;03m# Point 3\u001b[39;00m\n\u001b[1;32m     58\u001b[0m     [\u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m2.4\u001b[39m, \u001b[38;5;241m4.9\u001b[39m]     \u001b[38;5;66;03m# Point 4\u001b[39;00m\n\u001b[1;32m     59\u001b[0m ])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'a' is not defined"
     ]
    }
   ],
   "source": [
    "#test for scale \n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "def unit_cell_to_cartesian_matrix(aL,bL,cL,alpha,beta,gamma):\n",
    "    pi = np.pi\n",
    "    \"\"\"Convert unit cell parameters to a Cartesian transformation matrix.\"\"\"\n",
    "    aL,bL,cL,alpha,beta,gamma = list(map(float, (aL,bL,cL,alpha,beta,gamma)))\n",
    "    ax = aL\n",
    "    ay = 0.0\n",
    "    az = 0.0\n",
    "    bx = bL * np.cos(gamma * pi / 180.0)\n",
    "    by = bL * np.sin(gamma * pi / 180.0)\n",
    "    bz = 0.0\n",
    "    cx = cL * np.cos(beta * pi / 180.0)\n",
    "    cy = (cL * bL * np.cos(alpha * pi /180.0) - bx * cx) / by\n",
    "    cz = (cL ** 2.0 - cx ** 2.0 - cy ** 2.0) ** 0.5\n",
    "    unit_cell = np.asarray([[ax,ay,az],[bx,by,bz],[cx,cy,cz]]).T\n",
    "    return unit_cell\n",
    "\n",
    "def fractional_to_cartesian(fractional_coords, T):\n",
    "    \"\"\"Convert fractional coordinates to Cartesian using the transformation matrix.\"\"\"\n",
    "    return np.dot(fractional_coords, T.T)\n",
    "\n",
    "def cartesian_to_fractional(cartesian_coords, unit_cell_inv):\n",
    "    \"\"\"Convert Cartesian coordinates to fractional coordinates using the inverse transformation matrix.\"\"\"\n",
    "    return np.dot(cartesian_coords, unit_cell_inv.T)\n",
    "\n",
    "def objective_function(params, old_cell_params, old_cartesian_coords, new_cartesian_coords):\n",
    "    a_new, b_new, c_new, alpha_new, beta_new, gamma_new = params\n",
    "    a_old, b_old, c_old, alpha_old, beta_old, gamma_old = old_cell_params\n",
    "\n",
    "    # Compute transformation matrix for the old unit cell\n",
    "    T_old = unit_cell_to_cartesian_matrix(a_old, b_old, c_old, alpha_old, beta_old, gamma_old)\n",
    "    T_old_inv= np.linalg.inv(T_old)\n",
    "    #backup\n",
    "    old_fractional_coords = cartesian_to_fractional(old_cartesian_coords, T_old_inv)\n",
    "\n",
    "    # Compute transformation matrix for the new unit cell\n",
    "    T_new = unit_cell_to_cartesian_matrix(a_new, b_new, c_new, alpha_new, beta_new, gamma_new)\n",
    "    T_new_inv= np.linalg.inv(T_new)\n",
    "\n",
    "    # Convert the new Cartesian coordinates to fractional coordinate using the old unit cell\n",
    "    fractional_coords_new = cartesian_to_fractional(new_cartesian_coords, T_new_inv)\n",
    "\n",
    "    # Minimize the difference between the calculated new Cartesian coordinates and the provided new Cartesian coordinates\n",
    "    return np.sum(np.linalg.norm(fractional_coords_new - old_fractional_coords, axis=1)**2)\n",
    "\n",
    "# Example usage\n",
    "# Old cell parameters (example values)\n",
    "old_cell_params = [a, b, c, ang_alpha, ang_beta, ang_gamma]  # [a, b, c, alpha, beta, gamma]\n",
    "\n",
    "# Old Cartesian coordinates of points (example values)\n",
    "old_cartesian_coords = np.array([\n",
    "    [0.0, 0.0, 0.0],    # Point 1\n",
    "    [2.5, 3.0, 3.5],    # Point 2\n",
    "    [1.25, 1.5, 5.25],  # Point 3\n",
    "    [0.5, 2.4, 4.9]     # Point 4\n",
    "])\n",
    "\n",
    "\n",
    "# New Cartesian coordinates of the same points (example values)\n",
    "new_cartesian_coords = np.array([\n",
    "    [0.0, 0.0, 0.0],    # Point 1\n",
    "    [5, 6, 7],    # Point 2\n",
    "    [2.5, 3, 10.5],    # Point 3\n",
    "    [1, 4.8, 9.8]     # Point 4\n",
    "])\n",
    "\n",
    "# Initial guess for new unit cell parameters (e.g., slightly modified cell)\n",
    "initial_params = [4.5, 4.5, 4.5, 90.0, 90.0, 90.0]\n",
    "\n",
    "# Bounds: a, b, c > 0; angles [0, 180]\n",
    "bounds = [(0, None)] * 3 + [(20, 180)] * 3\n",
    "\n",
    "# Optimize using L-BFGS-B to minimize the objective function\n",
    "result = minimize(\n",
    "    objective_function,\n",
    "    x0=initial_params,\n",
    "    args=(old_cell_params, old_cartesian_coords, new_cartesian_coords),\n",
    "    method='L-BFGS-B',\n",
    "    bounds=bounds\n",
    ")\n",
    "\n",
    "# Extract optimized parameters\n",
    "optimized_params = np.round(result.x,5)\n",
    "print(\"Optimized New Cell Parameters:\", optimized_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#绕轴旋转失去的自由度,如果两个node是沿轴相邻,则第二个应该施加一个偏转矩阵,180度偏转为flip,3个cluster则旋转60相邻,以轴相邻组合的个数为变量决定偏转角度,这两个node合起来的质心应该在旋转轴上或者很近的距离\n",
    "#如果两个node是沿轴不相邻,则不考虑\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vlx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
