{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "from tests.MOF_builder.functions.ciftemplate2graph import ct2g,node_vecs\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import os\n",
    "import veloxchem as vlx\n",
    "import re\n",
    "from numpy.linalg import norm\n",
    "from tests.MOF_builder.functions.bbcif_properties import bb2array,X_vecs,selected_type_vecs\n",
    "from tests.MOF_builder.functions.place_bbs import superimpose,mag_superimpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.MOF_builder.functions.frag_recognizer import process_linker_molecule\n",
    "linker_file = 'ndi.xyz'\n",
    "molecule = vlx.Molecule.read_xyz_file(linker_file)\n",
    "linker_topic =2\n",
    "center_frag_nodes_num,center_Xs,single_frag_nodes_num,frag_Xs= process_linker_molecule(molecule,linker_topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pillar stack structure:\n",
    "#regarding chain_node cif file:\n",
    "    #find the pillar direction vector which is defined by the Al-Al vectors in chain_node cif file \n",
    "    #find the pair of x vectors, which are vertical to the pillar direction vector in chain_node cif file, could be more than one pairs\n",
    "    #find the Al-Al length, read from the cif file\n",
    "#regarding the linker cif file:\n",
    "    #find the length of the linker which should be the maximum length of X vectors in the linker cif file\n",
    "\n",
    "#regarding the template cif file:\n",
    "    #find the pillar direction which should be along the pure V-V direction (no Er node between) in the template cif file, \n",
    "    #find the edge vector in the template cif file, which should be Er-Er edge\n",
    "    #find the length of the edge vector in the template cif file\n",
    "    #fix one direction of the box, which should be parallel to the pilalar direction\n",
    "\n",
    "#the unit_cell of the template cif file should be scaled to fit the length of the linker, and the box_vector which along pillar direction should be fixed\n",
    "#when we want to place the node in the box, we should use a pair of x vectors which targets the connected V through the edge vector in the template cif file and the pillar direction vector, we use superimpose function to rotate and place the node at the right position\n",
    "#when we want to place the edge in the box, we should consider all of the x vectors placed in box and find the connected connected x vectors in two sidde of the Er-Er edge, then we use superimpose function to rotate and place the edge at the right position \n",
    "from tests.MOF_builder.functions.bbcif_properties import bb2array,selected_type_vecs,calc_edge_len\n",
    "from tests.MOF_builder.functions.place_bbs import superimpose\n",
    "\n",
    "chain_node_cif = '21Alchain.cif'\n",
    "template_cif = 'chain_rna.cif'\n",
    "linker_cif = 'edges/diedge.cif'\n",
    "#chain node\n",
    "#Al_vecs = selected_type_vecs(chain_node_cif,'.', 'Al',False)\n",
    "#chain_node_vecs = bb2array(chain_node_cif,'.')\n",
    "#chain_node_coords = np.asarray([i[1] for i in chain_node_vecs])\n",
    "#metal_cvec = Al_vecs[0]-Al_vecs[1]\n",
    "#node_pillar_cvec = metal_cvec/norm(metal_cvec) \n",
    "#node_x_vecs = selected_type_vecs(chain_node_cif,'.','X',False)\n",
    "\n",
    "\n",
    "##find the x vectors which are vertical to the pillar direction\n",
    "#xx_pairs = []\n",
    "#for i in range(0,len(x_vecs)):\n",
    "#    for j in range(i+1,len(x_vecs)):\n",
    "#        xx_vec = x_vecs[i]-x_vecs[j]\n",
    "#        xx_vec = xx_vec/norm(xx_vec)\n",
    "#        if np.dot(xx_vec,metal_cvec) < 1e-3:\n",
    "#            xx_pairs.append((i,j))\n",
    "#print(xx_pairs)\n",
    "\n",
    "\n",
    "#linker\n",
    "linker_x_vecs = selected_type_vecs(linker_cif,'.','X',False)\n",
    "#ditopic linker only has two x vectors\n",
    "linker_length = calc_edge_len(linker_cif,'.') #length of the edge should be x-x length in linker cif file, unit angstrom\n",
    "print(linker_length,'linker_length')\n",
    "\n",
    "###template\n",
    "##gen = ct2g('chain_rna.cif', 'tests/templates')\n",
    "##net = next(gen)\n",
    "##TG, start, unit_cell, TVT, TET, TNAME, a, b, c, ang_alpha, ang_beta, ang_gamma, max_le, catenation = net\n",
    "##\n",
    "##def updateTG2NG(TG):\n",
    "##    #ditopic linker should be connected to two V nodes directly \n",
    "##    #find path between two nodes which starts from V node to V node passing through Er nodes\n",
    "##    Vnodes = [n for n in TG.nodes() if n.startswith('V')]\n",
    "##    Ernodes = [n for n in TG.nodes() if n.startswith('Er')]\n",
    "##\n",
    "##    valid_paths = []\n",
    "##    Vnodes = [n for n in TG.nodes() if n.startswith('V')]\n",
    "##    for i in range(0, len(Vnodes)):\n",
    "##        for j in range(i+1, len(Vnodes)):\n",
    "##            source=Vnodes[i]\n",
    "##            target=Vnodes[j]\n",
    "##            path = nx.shortest_path(TG, source,target)\n",
    "##            if len(path) > 2:\n",
    "##                #if only two V nodes are there in the path passed Er, then it is a valid path\n",
    "##                if all([n.startswith('Er') for n in path[1:-1]]):\n",
    "##                    valid_paths.append(path)\n",
    "##\n",
    "##    NG = nx.Graph()\n",
    "##    edges_info=TG.edges(data=True)\n",
    "##    count = 0\n",
    "##    le=0\n",
    "##    pillars_cvecs = []\n",
    "##    pillars_fvecs = []\n",
    "##    edge_cvecs = []\n",
    "##    edge_fvecs = []\n",
    "##    for edge in edges_info:\n",
    "##        #node1,node2=edge[0],edge[1]\n",
    "##        edge_type=edge[2]['type']\n",
    "##        edge_label=edge[2]['label']\n",
    "##        edge_ccoord=edge[2]['ccoords']\n",
    "##        edge_fcoord=edge[2]['fcoords']\n",
    "##        edge_length=edge[2]['length']\n",
    "##        edge_index=edge[2]['index']\n",
    "##        edge_pd = edge[2]['pd']\n",
    "##        node1,node2 = edge_pd\n",
    "##    \n",
    "##        if edge_type[0]==edge_type[1]:\n",
    "##            #V-V find the pillar direction which should be along the pure V-V direction (no Er node between) in the template cif file\n",
    "##            if edge_type[0]=='V':# chain of metal nodes\n",
    "##                #print(node1,node2,edge_type,edge_fcoord,edge_length,edge_index,edge_pd)\n",
    "##                #name = node1+node2+'_'+str(count)\n",
    "##                name = int(count)\n",
    "##                pillars_cvecs.append(TG.nodes[node1]['ccoords']-TG.nodes[node2]['ccoords'])\n",
    "##                pillars_fvecs.append(TG.nodes[node1]['fcoords']-TG.nodes[node2]['fcoords'])\n",
    "##                NG.add_node(name, label = (node1,node2),type=edge_type, index=edge_index, ccoords=edge_ccoord, fcoords=edge_fcoord, cn=[], cifname=[])\n",
    "##                count+=1\n",
    "##            #Er-Er find the edge vector in the template cif file, which should be Er-Er edge\n",
    "##            else:\n",
    "##                le = max(edge_length,le) #find the length of the edge vector in the template cif file\n",
    "##                edge_cvecs.append(TG.nodes[node1]['ccoords']-TG.nodes[node2]['ccoords'])\n",
    "##                edge_fvecs.append(TG.nodes[node1]['fcoords']-TG.nodes[node2]['fcoords'])\n",
    "##                pass\n",
    "##                #edge direction \n",
    "##                #print(node1,node2,edge_type,edge_fcoord,edge_length,edge_index,edge_pd)\n",
    "##                #get evecs\n",
    "##\n",
    "##        else:\n",
    "##            #ignore Er-V\n",
    "##            #print(node1,node2,edge_type)\n",
    "##            pass\n",
    "##\n",
    "##    #in NG any VV node has 'V5' should be connected to antoher VV node with 'V11' and 'V12'\n",
    "##    for path in valid_paths:\n",
    "##        source = path[0]\n",
    "##        target = path[-1]\n",
    "##        #in NG any VV node has source should be connected to antoher VV node with target\n",
    "##        vv_source_nodes = [node for node in NG.nodes() if source in NG.nodes[node]['label']]\n",
    "##        vv_target_nodes = [node for node in NG.nodes() if target in NG.nodes[node]['label']]\n",
    "##        #connect any source node to any target node\n",
    "##\n",
    "##\n",
    "##    #find the pillar direction which should be along the pure V-V direction (no Er node between) in the template cif file\n",
    "##    count = 1\n",
    "##    edges_cvecs=[]\n",
    "##    edges_fvecs=[]\n",
    "##    for vv_source_node in vv_source_nodes:\n",
    "##        for vv_target_node in vv_target_nodes:\n",
    "##            fcoord = (NG.nodes[vv_source_node]['fcoords'],NG.nodes[vv_target_node]['fcoords'])\n",
    "##            ccoord = (NG.nodes[vv_source_node]['ccoords'],NG.nodes[vv_target_node]['ccoords'])\n",
    "##            edges_cvecs.append(NG.nodes[vv_target_node]['ccoords']- NG.nodes[vv_source_node]['ccoords'])\n",
    "##            edges_fvecs.append(NG.nodes[vv_target_node]['fcoords']- NG.nodes[vv_source_node]['fcoords'])\n",
    "##            lbl = [0,0,0]\n",
    "##            NG.add_edge(vv_source_node,vv_target_node,key=(count,lbl[0],lbl[1],lbl[2]), label=lbl , length=le, fcoords=fcoord, ccoords=ccoord, index=count, pd=(vv_source_node,vv_target_node))\n",
    "##            count+=1\n",
    "##    return NG,pillars_cvecs\n",
    "####\n",
    "####NG,pillars_cvecs = updateTG2NG(TG)\n",
    "#####fix one direction of the box, which should be parallel to the pilalar direction\n",
    "####\n",
    "####\n",
    "####\n",
    "#####the unit_cell of the template cif file should be scaled to fit the length of the linker, and the box_vector which along pillar direction should be fixed\n",
    "####\n",
    "####\n",
    "#####find the pillar direction which should be along the pure V-V direction (no Er node between) in the template cif file\n",
    "####\n",
    "##\n",
    "###find the pillar direction which should be along the pure V-V direction (no Er node between) in the template cif file\n",
    "##\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tests.MOF_builder.functions._readcif import extract_type_atoms_array_in_primitive_cell,read_cif,extract_atoms_xyz_from_lines,extract_quote_lines,extract_symmetry_operation_from_lines,apply_sym_operator\n",
    "import numpy as np\n",
    "\n",
    "target_type = 'Al'\n",
    "cell_info, array_atom, array_target_atoms=extract_type_atoms_array_in_primitive_cell(chain_node_cif, target_type)\n",
    "_,_, node_x_vecs=extract_type_atoms_array_in_primitive_cell(chain_node_cif, 'X')\n",
    "\n",
    "cell_info, symmetry_sector, atom_site_sector = read_cif(chain_node_cif)\n",
    "array_atom, array_xyz = extract_atoms_xyz_from_lines(atom_site_sector)\n",
    "node_com = np.mean(array_target_atoms, axis=0)\n",
    "chain_node_fcoords = array_xyz - node_com\n",
    "\n",
    "metal_cvec = array_target_atoms[0]-array_target_atoms[1]\n",
    "node_pillar_cvec = metal_cvec/norm(metal_cvec) \n",
    "node_x_vecs = node_x_vecs - node_com\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "from tests.MOF_builder.functions._readcif import extract_type_atoms_array_in_primitive_cell\n",
    "from scipy.spatial.distance import pdist\n",
    "from scipy.cluster.hierarchy import linkage\n",
    "from scipy.cluster.hierarchy import fcluster\n",
    "\n",
    "cif_file ='MIL53templatecif.cif'\n",
    "target_type = 'YY'\n",
    "cluster_distance_threshhold = 0.1\n",
    "\n",
    "# use cell_info to generate the matrix for the unit cell to get cartesian coordinates\n",
    "def make_supercell_3x3x3(array_xyz):\n",
    "    array_x1 = array_xyz + np.array([1, 0, 0])\n",
    "    array_x2 = array_xyz + np.array([-1, 0, 0])\n",
    "    array_y1 = array_xyz + np.array([0, 1, 0])\n",
    "    array_y2 = array_xyz + np.array([0, -1, 0])\n",
    "    array_x1_y1 = array_xyz + np.array([1, 1, 0])\n",
    "    array_x1_y2 = array_xyz + np.array([1, -1, 0])\n",
    "    array_x2_y1 = array_xyz + np.array([-1, 1, 0])\n",
    "    array_x2_y2 = array_xyz + np.array([-1, -1, 0])\n",
    "    \n",
    "    layer_3x3 = np.vstack((\n",
    "        array_xyz,\n",
    "        array_x1,\n",
    "        array_x2,\n",
    "        array_y1,\n",
    "        array_y2,\n",
    "        array_x1_y1,\n",
    "        array_x1_y2,\n",
    "        array_x2_y1,\n",
    "        array_x2_y2\n",
    "    ))\n",
    "    \n",
    "    layer_3x3_z1 = layer_3x3 + np.array([0, 0, 1])\n",
    "    layer_3x3_z2 = layer_3x3 + np.array([0, 0, -1])\n",
    "    \n",
    "    supercell_3x3x3 = np.vstack((\n",
    "        layer_3x3,\n",
    "        layer_3x3_z1,\n",
    "        layer_3x3_z2\n",
    "    ))\n",
    "    \n",
    "    return supercell_3x3x3\n",
    "\n",
    "def extract_unit_cell(cell_info):\n",
    "    pi = np.pi\n",
    "    aL, bL, cL, alpha, beta, gamma = cell_info\n",
    "    aL,bL,cL,alpha,beta,gamma = list(map(float, (aL,bL,cL,alpha,beta,gamma)))\n",
    "    ax = aL\n",
    "    ay = 0.0\n",
    "    az = 0.0\n",
    "    bx = bL * np.cos(gamma * pi / 180.0)\n",
    "    by = bL * np.sin(gamma * pi / 180.0)\n",
    "    bz = 0.0\n",
    "    cx = cL * np.cos(beta * pi / 180.0)\n",
    "    cy = (cL * bL * np.cos(alpha * pi /180.0) - bx * cx) / by\n",
    "    cz = (cL ** 2.0 - cx ** 2.0 - cy ** 2.0) ** 0.5\n",
    "    unit_cell = np.asarray([[ax,ay,az],[bx,by,bz],[cx,cy,cz]]).T\n",
    "    return unit_cell\n",
    "# a function, given an array of atoms, use distance to find the clusters of atoms, and return the center of the cluster, we can set a distance thereshold to define the cluster\n",
    "def find_cluster_center(array_atom):\n",
    "    array_atom = np.array(array_atom,dtype=float)\n",
    "    center = np.mean(array_atom,axis=0)\n",
    "    return center\n",
    "\n",
    "def clust_analysis_points(array_atom,distance_threshhold):\n",
    "    #use scipy.cluster distance, to cluster the points\n",
    "    #find the distance matrix\n",
    "    dist = pdist(array_atom)\n",
    "    #find the linkage matrix\n",
    "    Z = linkage(dist, 'ward')\n",
    "    #find the cluster\n",
    "    cluster = fcluster(Z, distance_threshhold, criterion='distance')\n",
    "    #find the center of the cluster\n",
    "    cluster_center = []\n",
    "    for i in range(1,max(cluster)+1):\n",
    "        cluster_center.append(find_cluster_center(array_atom[cluster==i]))\n",
    "    return cluster_center\n",
    "\n",
    "def extract_cluster_center_from_templatecif(cif_file, target_type,cluster_distance_threshhold):\n",
    "    cell_info, array_atom, array_target_atoms =extract_type_atoms_array_in_primitive_cell(cif_file, target_type)\n",
    "    unit_cell = extract_unit_cell(cell_info)\n",
    "    unit_cell = np.round(unit_cell,3)\n",
    "    metal333 = make_supercell_3x3x3(array_target_atoms)\n",
    "    metal333 = np.vstack(metal333)\n",
    "    #cluster analysis in cartesian coordinates\n",
    "    array_metal_ccords = np.dot(unit_cell,metal333.T).T\n",
    "    cluster_centers_ccoords=clust_analysis_points(array_metal_ccords,cluster_distance_threshhold)\n",
    "    cluster_centers_ccoords = np.vstack(cluster_centers_ccoords)\n",
    "    #cluster_centers should return fractional coordinates\n",
    "    cluster_centers_fcoords = np.dot(np.linalg.inv(unit_cell),cluster_centers_ccoords.T).T\n",
    "    #filter cluster centers which is inside the unit cell, boundary condition is [-0.01,1.01]\n",
    "    cluster_centers_fcoords = [c for c in cluster_centers_fcoords if all([i>=-0.01 and i<=1.01 for i in c])]\n",
    "    cluster_centers_fcoords = np.mod(cluster_centers_fcoords,1)\n",
    "    cluster_centers_fcoords = np.round(cluster_centers_fcoords,3)\n",
    "    cluster_centers_fcoords = np.unique(cluster_centers_fcoords,axis=0)\n",
    "    return cluster_centers_fcoords,cell_info,unit_cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vvnode,cell_info,unit_cell = extract_cluster_center_from_templatecif(cif_file, 'YY',1)\n",
    "eenode,_,_ = extract_cluster_center_from_templatecif(cif_file, 'XX',1)\n",
    "\n",
    "#loop over super333xxnode and super333yynode to find the pair of x node in unicell which pass through the yynode\n",
    "vvnode333 = make_supercell_3x3x3(vvnode)\n",
    "eenode333 = make_supercell_3x3x3(eenode)\n",
    "#find pair of x, pass y, which means y is the edge center between two x \n",
    "\n",
    "#for each y, find nearest x in xxnode333, then check if the center of the pair of x is around y, if yes, the it is valid pair of x\n",
    "def check_inside_unit_cell(point):\n",
    "    return all([i>=-0.01 and i<=1.01 for i in point])\n",
    "\n",
    "#check if after np.mod, the fcoords is the same as before\n",
    "def check_moded_fcoords(point):\n",
    "    x,y,z = point[0],point[1],point[2]\n",
    "    if np.mod(x,1)!=x:\n",
    "        return False\n",
    "    if np.mod(y,1)!=y:\n",
    "        return False  \n",
    "    if np.mod(z,1)!=z:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def find_pair_v_e(vvnode333, eenode333):\n",
    "    G = nx.Graph()\n",
    "    pair_ve = []\n",
    "    for e in eenode333:\n",
    "        dist = np.linalg.norm(vvnode333 - e, axis=1)\n",
    "        # find two v which are nearest to e, and at least one v is in [0,1] unit cell\n",
    "        v1 = vvnode333[np.argmin(dist)]\n",
    "        v1_idx = np.argmin(dist)\n",
    "        dist[np.argmin(dist)] = 1000\n",
    "        v2 = vvnode333[np.argmin(dist)]\n",
    "        v2_idx = np.argmin(dist)\n",
    "        # find the center of the pair of v\n",
    "        center = (v1 + v2) / 2\n",
    "        # check if there is a v in [0,1] unit cell\n",
    "        if check_inside_unit_cell(v1) or check_inside_unit_cell(v2):\n",
    "            # check if the center of the pair of v is around e\n",
    "            if np.linalg.norm(center - e) < 1e-3:\n",
    "                G.add_node(v1_idx, fcoords=v1)\n",
    "                G.add_node(v2_idx, fcoords=v2)\n",
    "                G.add_edge(v1_idx, v2_idx, fcoords=(v1, v2),fc_center=e),\n",
    "                pair_ve.append((v1, v2, e))\n",
    "    return pair_ve, len(pair_ve), G\n",
    "\n",
    "#add ccoords to the the nodes in the graph\n",
    "def add_ccoords(G,unit_cell):\n",
    "    for n in G.nodes():\n",
    "        G.nodes[n]['ccoords'] = np.dot(unit_cell,G.nodes[n]['fcoords'])\n",
    "    return G\n",
    "\n",
    "def set_DV_V(G):\n",
    "    for n in G.nodes():\n",
    "        if G.degree(n) == max(dict(G.degree()).values()):\n",
    "            #G.nodes[n]['type'] = 'V'\n",
    "            #check if the moded ccoords is in the unit cell\n",
    "            if check_moded_fcoords(G.nodes[n]['fcoords']):\n",
    "                G.nodes[n]['type'] = 'V'\n",
    "            else:\n",
    "                G.nodes[n]['type'] = 'DV'\n",
    "        else:\n",
    "            G.nodes[n]['type'] = 'DV'\n",
    "    return G\n",
    "\n",
    "#check e in G, find e in unit_cell, use np.mod to filter the e in unit_cell, set the valid e with E type, others are DE type\n",
    "def set_DE_E(G):\n",
    "    all_e =[]\n",
    "    for e in G.edges():\n",
    "        all_e.append(G.edges[e]['fc_center'])\n",
    "    all_e = np.vstack(all_e)\n",
    "    all_e = np.mod(all_e,1)\n",
    "    unique_e = np.unique(all_e,axis=0)\n",
    "    for e in G.edges():\n",
    "        if np.any(np.all(np.isclose(G.edges[e]['fc_center'],unique_e),axis=1)):\n",
    "            G.edges[e]['type'] = 'E'\n",
    "        else:\n",
    "            G.edges[e]['type'] = 'DE'\n",
    "    return G\n",
    "\n",
    "\n",
    "\n",
    "pair_vv_e,_,G=find_pair_v_e(vvnode333,eenode333)\n",
    "G = add_ccoords(G,unit_cell)\n",
    "G = set_DV_V(G)\n",
    "G = set_DE_E(G)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check connectivity of each node in G\n",
    "def check_connectivity(G):\n",
    "    for n in G.nodes():\n",
    "        print(n,G.nodes[n],G.degree(n))\n",
    "#check_connectivity(G) #debug\n",
    "\n",
    "#check edge information in G\n",
    "def check_edge(G):\n",
    "    for e in G.edges():\n",
    "        print(e,G.edges[e])\n",
    "check_edge(G) #debug\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#firstly, check if all V nodes have highest connectivity\n",
    "#secondly, sort all DV nodes by connectivity\n",
    "def sort_nodes_by_type_connectivity(G):\n",
    "    Vnodes = [n for n in G.nodes() if G.nodes[n]['type']=='V']\n",
    "    DVnodes = [n for n in G.nodes() if G.nodes[n]['type']=='DV']\n",
    "    Vnodes = sorted(Vnodes,key=lambda x: G.degree(x),reverse=True)\n",
    "    DVnodes = sorted(DVnodes,key=lambda x: G.degree(x),reverse=True)\n",
    "    return Vnodes+DVnodes\n",
    "sorted_nodes = sort_nodes_by_type_connectivity(G)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fix one direction of the box, which should be parallel to the pilalar direction\n",
    "\n",
    "#rotate the node to pillar direction and put all nodes into the cartesian coordinate \n",
    "def check_edge_inunitcell(e):\n",
    "    if 'DV' in G.nodes[e[0]]['type'] or 'DV' in G.nodes[e[1]]['type']:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def find_and_sort_edges_bynodeconnectivity(graph, sorted_nodes):\n",
    "    all_edges = list(graph.edges())\n",
    "\n",
    "    sorted_edges = []\n",
    "    #add unit_cell edge first\n",
    "\n",
    "    ei = 0\n",
    "    while ei < len(all_edges):\n",
    "            e = all_edges[ei]\n",
    "            if check_edge_inunitcell(e):\n",
    "                sorted_edges.append(e)\n",
    "                all_edges.pop(ei)\n",
    "            ei += 1\n",
    "    #sort edge by sorted_nodes\n",
    "    for n in sorted_nodes:\n",
    "        ei = 0\n",
    "        while ei < len(all_edges):\n",
    "            e = all_edges[ei]\n",
    "            if n in e:\n",
    "                if n ==e[0]:\n",
    "                    sorted_edges.append(e)\n",
    "                else:\n",
    "                    sorted_edges.append((int(e[1]),int(e[0])))\n",
    "                all_edges.pop(ei)\n",
    "            else:\n",
    "                ei += 1\n",
    "\n",
    "    return sorted_edges    \n",
    "    \n",
    "sorted_edges = find_and_sort_edges_bynodeconnectivity(G,sorted_nodes)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#debug\n",
    "###save the sorted nodes ccoords as xyz\n",
    "##def save_node_xyz(sorted_nodes,unit_cell,G):\n",
    "##    with open('sorted_nodes.xyz','w') as f:\n",
    "##        f.write(str(len(sorted_nodes))+'\\n')\n",
    "##        f.write('sorted_nodes\\n')\n",
    "##        for n in sorted_nodes:\n",
    "##            ccoords = np.dot(unit_cell,G.nodes[n]['fcoords']).tolist()\n",
    "##            f.write('V'+str(sorted_nodes.index(n))+'    '+' '.join(map(str,ccoords))+'\\n')\n",
    "##save_node_xyz(sorted_nodes,unit_cell,G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loop node in G, for each node, find the nearest node, and calculte the node_node vector, check if all of the pair vector are parallel\n",
    "\n",
    "def check_if_pillarstack(G):\n",
    "    node_node_vec = []\n",
    "    for n in G.nodes():\n",
    "        if 'DV' in G.nodes[n]['type']:\n",
    "            continue\n",
    "        dist = []\n",
    "        for nn in G.nodes():\n",
    "            dist.append(np.linalg.norm(G.nodes[n]['fcoords']-G.nodes[nn]['fcoords']))\n",
    "        dist = np.array(dist)\n",
    "        if np.min(dist) < 1e-3:\n",
    "            dist[np.argmin(dist)] = 1000\n",
    "        if np.min(dist) > 1:\n",
    "            continue\n",
    "\n",
    "        nn = list(G.nodes())[np.argmin(dist)]\n",
    "        node_node = G.nodes[n]['fcoords']-G.nodes[nn]['fcoords']\n",
    "        node_node = node_node/norm(node_node)\n",
    "        node_node_vec.append(node_node)\n",
    "        \n",
    "    #check if all of the pair vector are parallel\n",
    "    for i in range(0,len(node_node_vec)):\n",
    "        for j in range(i+1,len(node_node_vec)):\n",
    "            if norm(np.cross(node_node_vec[i],node_node_vec[j])) > 1e-3:\n",
    "                print('not pillar stack')\n",
    "                return False,None\n",
    "    pillar_vec = np.abs(node_node_vec[0])\n",
    "    print('pillar stack',pillar_vec)\n",
    "    return True,pillar_vec\n",
    "\n",
    "\n",
    "PILLAR,pillar_vec = check_if_pillarstack(G)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "beginning_point = [0.0,0.0,0.0]\n",
    "rms,rot,tran = superimpose([beginning_point,node_pillar_cvec],[beginning_point,pillar_vec])\n",
    "pillar_oriented_nodexvec=np.dot(np.asarray(node_x_vecs),rot)\n",
    "pillar_oriented_node_xcoords = np.dot(unit_cell,pillar_oriented_nodexvec.T).T\n",
    "pillar_oriented_node_fcoords = np.dot(chain_node_fcoords,rot)\n",
    "pillar_oriented_node_coords = np.dot(unit_cell,pillar_oriented_node_fcoords.T).T\n",
    "nodexxxx = []\n",
    "xxxx_positions_dict = {}\n",
    "chain_node_positions_dict = {}\n",
    "chain_node_positions = []\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add row indices as the first column\n",
    "def addidx(array):\n",
    "    row_indices = np.arange(array.shape[0]).reshape(-1, 1).astype(int)\n",
    "\n",
    "    new_array = np.hstack((row_indices, array))\n",
    "    return new_array\n",
    "\n",
    "#reindex the nodes in the xxxx_positions with the index in the sorted_nodes, like G has 16 nodes[2,5,7], but the new dictionary should be [0,1,2]\n",
    "xxxx_positions_dict = {sorted_nodes.index(n):addidx(G.nodes[n]['ccoords']+pillar_oriented_node_xcoords) for n in sorted_nodes}\n",
    "chain_node_positions_dict = {sorted_nodes.index(n):G.nodes[n]['ccoords']+pillar_oriented_node_coords for n in sorted_nodes}\n",
    "#reindex the edges in the G with the index in the sorted_nodes\n",
    "sorted_edges = [(sorted_nodes.index(e[0]),sorted_nodes.index(e[1])) for e in sorted_edges]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize, linear_sum_assignment\n",
    "import networkx as nx\n",
    "\n",
    "\n",
    "def reorthogonalize_matrix(matrix):\n",
    "    \"\"\"\n",
    "    Ensure the matrix is a valid rotation matrix with determinant = 1.\n",
    "    \"\"\"\n",
    "    U, _, Vt = np.linalg.svd(matrix)\n",
    "    R = np.dot(U, Vt)\n",
    "    if np.linalg.det(R) < 0:\n",
    "        U[:, -1] *= -1\n",
    "        R = np.dot(U, Vt)\n",
    "    return R\n",
    "\n",
    "\n",
    "def sort_solver_by_cost(cost_matrix,pairs):\n",
    "    #find the row and column index of the minimum value in the cost matrix\n",
    "    #get the solver of hungarian algorithm (but #the solver is from the first row)\n",
    "    #sort by cost_matrix[i,j] sort the result from the minimum cost to the maximum cost\n",
    "    #the result is the pair of the row and column index\n",
    "    costs = []\n",
    "    for i in range(len(pairs)):\n",
    "        row,column = pairs[i]\n",
    "        costs.append(cost_matrix[row,column])\n",
    "    sorted_idx = np.argsort(costs)\n",
    "    sorted_pairs = [pairs[idx] for idx in sorted_idx]\n",
    "    return sorted_pairs\n",
    "\n",
    "def locate_min_idx(a_array):\n",
    "    row_idx = np.argmin(a_array)\n",
    "    print(row_idx)\n",
    "    print(a_array.shape)\n",
    "    col_idx = np.argmin(a_array[row_idx])\n",
    "    return row_idx,col_idx\n",
    "\n",
    "def find_optimal_pairings(node_i_positions, node_j_positions):\n",
    "    \"\"\"\n",
    "    Find the optimal one-to-one pairing between atoms in two nodes using the Hungarian algorithm.\n",
    "    \"\"\"\n",
    "    num_i, num_j = len(node_i_positions), len(node_j_positions)\n",
    "    cost_matrix = np.zeros((num_i, num_j))\n",
    "    for i in range(num_i):\n",
    "        for j in range(num_j):\n",
    "            cost_matrix[i, j] = np.linalg.norm(node_i_positions[i,1:] - node_j_positions[j,1:])\n",
    "\n",
    "    #row_ind, col_ind = linear_sum_assignment(cost_matrix)\n",
    "    print(cost_matrix.shape)\n",
    "    row_ind, col_ind = locate_min_idx(cost_matrix)\n",
    "    print(row_ind,col_ind,cost_matrix)\n",
    "  \n",
    "\n",
    "    return [row_ind,col_ind]\n",
    "\n",
    "#after test, we find that we cannot get an exclusive pair, because of the bad initial guess\n",
    "##def update_pairs(pairs,atom_positions,i,j):\n",
    "##    nodeA_idx_set = atom_positions[i][:,0]\n",
    "##    nodeB_idx_set = atom_positions[j][:,0]\n",
    "##    correct_idx_pair =[]\n",
    "##    for k in range(len(pairs)):\n",
    "##        idx_A,idx_B = nodeA_idx_set[pairs[k][0]],nodeB_idx_set[pairs[k][1]]\n",
    "##        correct_idx_pair.append((idx_A,idx_B))\n",
    "##    return correct_idx_pair\n",
    "\n",
    "def find_edge_pairings(sorted_edges, atom_positions):\n",
    "    \"\"\"\n",
    "    Identify optimal pairings for each edge in the graph.\n",
    "\n",
    "    Parameters:\n",
    "        G (networkx.Graph): Graph structure with edges between nodes.\n",
    "        atom_positions (dict): Positions of X atoms for each node.\n",
    "\n",
    "    Returns:\n",
    "        dict: Mapping of edges to optimal atom pairs.\n",
    "              Example: {(0, 1): [(0, 3), (1, 2)], ...}\n",
    "    \"\"\"\n",
    "\n",
    "    edge_pairings = {}\n",
    "    \n",
    "    for i, j in sorted_edges:\n",
    "        node_i_positions = atom_positions[i] #[index,x,y,z]\n",
    "        node_j_positions = atom_positions[j] #[index,x,y,z]\n",
    "\n",
    "\n",
    "        # Find optimal pairings for this edge\n",
    "        \n",
    "        pairs = find_optimal_pairings(node_i_positions, node_j_positions)\n",
    "        print(sorted_nodes[i],sorted_nodes[j],pairs)\n",
    "        edge_pairings[(i, j)] = pairs #update_pairs(pairs,atom_positions,i,j)\n",
    "        #idx_0,idx_1 = pairs[0]\n",
    "        #x_idx_0 = atom_positions[i][idx_0][0]\n",
    "        #x_idx_1 = atom_positions[j][idx_1][0]\n",
    " #\n",
    "        #edge_pairings[(i, j)] = update_pairs(pairs,atom_positions,i,j) #but only first pair match\n",
    "        #atom_positions[i] = np.delete(atom_positions[i], idx_0, axis=0)\n",
    "        #atom_positions[j] = np.delete(atom_positions[j], idx_1, axis=0)\n",
    "\n",
    "    return edge_pairings\n",
    "\n",
    "\n",
    "def axis_rotation_matrix(axis, theta):\n",
    "    \"\"\"\n",
    "    Compute the rotation matrix for a rotation around an axis by an angle theta.\n",
    "\n",
    "    Parameters:\n",
    "        axis (tuple): The axis vector (a, b, c).\n",
    "        theta (float): The rotation angle in radians.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: The 3x3 rotation matrix.\n",
    "    \"\"\"\n",
    "    a, b, c = axis\n",
    "    axis = np.array([a, b, c])\n",
    "    axis = axis / np.linalg.norm(axis)  # Normalize the axis vector\n",
    "    a, b, c = axis\n",
    "\n",
    "    cos_theta = np.cos(theta)\n",
    "    sin_theta = np.sin(theta)\n",
    "    I = np.eye(3)\n",
    "    K = np.array([\n",
    "        [0, -c, b],\n",
    "        [c, 0, -a],\n",
    "        [-b, a, 0]\n",
    "    ])\n",
    "    \n",
    "    R = I + sin_theta * K + (1 - cos_theta) * np.dot(K, K)\n",
    "    return R\n",
    "\n",
    "def axis_objective_function(thetas, axis, static_atom_positions, sorted_edges):\n",
    "    \"\"\"\n",
    "    Objective function to minimize distances between paired atoms along edges.\n",
    "\n",
    "    Parameters:\n",
    "        theta (float): The rotation angle in radians.\n",
    "        axis (tuple): The axis vector (a, b, c).\n",
    "        G (networkx.Graph): Graph structure.\n",
    "        static_atom_positions (dict): Original positions of X atoms for each node.\n",
    "        edge_pairings (dict): Precomputed pairings for each edge.\n",
    "\n",
    "    Returns:\n",
    "        float: Total distance metric to minimize.\n",
    "    \"\"\"\n",
    "    total_distance = 0.0\n",
    "\n",
    "    for (i, j) in sorted_edges:\n",
    "        R_i = reorthogonalize_matrix(axis_rotation_matrix(axis, thetas[i]))\n",
    "        R_j = reorthogonalize_matrix(axis_rotation_matrix(axis, thetas[j]))\n",
    "\n",
    "        com_i = G.nodes[sorted_nodes[i]]['ccoords']\n",
    "        com_j = G.nodes[sorted_nodes[j]]['ccoords']\n",
    "\n",
    "        # Rotate positions around their mass center\n",
    "        rotated_i_positions = np.dot(static_atom_positions[i][:,1:] - com_i, R_i.T) + com_i\n",
    "        rotated_j_positions = np.dot(static_atom_positions[j][:,1:] - com_j, R_j.T) + com_j\n",
    "\n",
    "        for idx_i in range(len(rotated_i_positions)):\n",
    "            for idx_j in range(len(rotated_j_positions)):\n",
    "                dist = np.linalg.norm(rotated_i_positions[int(idx_i)] - rotated_j_positions[int(idx_j)])\n",
    "                total_distance += dist ** 2\n",
    "\n",
    "    return total_distance\n",
    "\n",
    "def _axis_objective_function(thetas, axis, static_atom_positions, edge_pairings):\n",
    "    \"\"\"\n",
    "    Objective function to minimize distances between paired atoms along edges.\n",
    "\n",
    "    Parameters:\n",
    "        theta (float): The rotation angle in radians.\n",
    "        axis (tuple): The axis vector (a, b, c).\n",
    "        G (networkx.Graph): Graph structure.\n",
    "        static_atom_positions (dict): Original positions of X atoms for each node.\n",
    "        edge_pairings (dict): Precomputed pairings for each edge.\n",
    "\n",
    "    Returns:\n",
    "        float: Total distance metric to minimize.\n",
    "    \"\"\"\n",
    "    total_distance = 0.0\n",
    "\n",
    "    for (i, j), pairs in edge_pairings.items():\n",
    "        R_i = reorthogonalize_matrix(axis_rotation_matrix(axis, thetas[i]))\n",
    "        R_j = reorthogonalize_matrix(axis_rotation_matrix(axis, thetas[j]))\n",
    "\n",
    "        com_i = G.nodes[sorted_nodes[i]]['ccoords']\n",
    "        com_j = G.nodes[sorted_nodes[j]]['ccoords']\n",
    "\n",
    "        # Rotate positions around their mass center\n",
    "        rotated_i_positions = np.dot(static_atom_positions[i][:,1:] - com_i, R_i.T) + com_i\n",
    "        rotated_j_positions = np.dot(static_atom_positions[j][:,1:] - com_j, R_j.T) + com_j\n",
    "\n",
    "        for idx_i, idx_j in pairs:\n",
    "            dist = np.linalg.norm(rotated_i_positions[int(idx_i)] - rotated_j_positions[int(idx_j)])\n",
    "            total_distance += dist ** 2\n",
    "\n",
    "    return total_distance\n",
    "\n",
    "\n",
    "def axis_optimize_rotations(axis, num_nodes,sorted_edges, atom_positions):\n",
    "    \"\"\"\n",
    "    Optimize the rotation angles around a given axis to minimize the difference between\n",
    "    rotated and target positions for each node.\n",
    "\n",
    "    Parameters:\n",
    "        axis (tuple): The axis vector (a, b, c).\n",
    "        G (networkx.Graph): Graph structure.\n",
    "        static_atom_positions (dict): Original positions of X atoms for each node.\n",
    "        edge_pairings (dict): Precomputed pairings for each edge.\n",
    "        initial_thetas (numpy.ndarray): Initial guesses for the rotation angles.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: The optimized rotation angles for each node.\n",
    "    \"\"\"\n",
    "    initial_thetas = np.zeros(num_nodes) # Initial guess for rotation angles\n",
    "    static_atom_positions = atom_positions.copy()\n",
    "    # Precompute edge-specific pairings\n",
    "    #edge_pairings = find_edge_pairings(sorted_edges, atom_positions)\n",
    "    result = minimize(axis_objective_function, initial_thetas, \n",
    "                      args=(axis,  static_atom_positions, sorted_edges), \n",
    "                      method='L-BFGS-B',options={\"maxiter\": 5000, \"disp\": True})\n",
    "    optimized_thetas = result.x\n",
    "\n",
    "    # Compute the rotation matrices for each node\n",
    "    optimized_rotations = [reorthogonalize_matrix(axis_rotation_matrix(axis, theta)) for theta in optimized_thetas]\n",
    "    \n",
    "    \n",
    "    # Return the optimized rotation matrices \n",
    "\n",
    "    return optimized_rotations\n",
    "\n",
    "def compute_rotation_with_pairing(connected_nodes, atom_positions,current_rotation_matrix):\n",
    "    \"\"\"\n",
    "    Compute the optimal rotation matrix for node pairs, starting from the current rotation matrix.\n",
    "    \n",
    "    Parameters:\n",
    "        node_i_positions (numpy.ndarray): Positions of X atoms in node i (Nx3 array).\n",
    "        node_j_positions (numpy.ndarray): Positions of X atoms in node j (Mx3 array).\n",
    "        current_rotation_matrix (numpy.ndarray): The current 3x3 rotation matrix for node i.\n",
    "\n",
    "    Returns:\n",
    "        rotation_matrix (numpy.ndarray): Optimized 3x3 rotation matrix for node i.\n",
    "    \"\"\"\n",
    "    \n",
    "    i, j = connected_nodes\n",
    "    # Extract paired positions\n",
    "    paired_node_i = atom_positions[i][:,1:]\n",
    "    paired_node_j = atom_positions[j][:,1:]\n",
    "\n",
    "    # Compute the centers of mass for both sets\n",
    "    com_i = np.mean(paired_node_i, axis=0)\n",
    "    com_j = np.mean(paired_node_j, axis=0)\n",
    "\n",
    "    # Translate positions to the center of mass\n",
    "    translated_i = paired_node_i - com_i\n",
    "    translated_j = paired_node_j - com_j\n",
    "\n",
    "    # Apply the current rotation matrix to node_i's positions\n",
    "    rotated_translated_i = np.dot(translated_i, current_rotation_matrix.T)\n",
    "\n",
    "    # Compute covariance matrix and SVD\n",
    "    H = np.dot(rotated_translated_i.T, translated_j)\n",
    "    U, _, Vt = np.linalg.svd(H)\n",
    "    R = np.dot(U, Vt)\n",
    "\n",
    "    # Ensure the resulting matrix is a valid rotation matrix (det = 1)\n",
    "    if np.linalg.det(R) < 0:\n",
    "        U[:, -1] *= -1\n",
    "        R = np.dot(U, Vt)\n",
    "\n",
    "    # Update the rotation matrix by combining the current and incremental rotation\n",
    "    optimized_rotation_matrix = np.dot(R, current_rotation_matrix)\n",
    "\n",
    "    return optimized_rotation_matrix\n",
    "\n",
    "def objective_function(params, G, static_atom_positions, sorted_edges):\n",
    "    \"\"\"\n",
    "    Objective function to minimize distances between paired atoms along edges.\n",
    "\n",
    "    Parameters:\n",
    "        params (numpy.ndarray): Flattened array of rotation matrices.\n",
    "        G (networkx.Graph): Graph structure.\n",
    "        atom_positions (dict): Original positions of X atoms for each node.\n",
    "        edge_pairings (dict): Precomputed pairings for each edge.\n",
    "\n",
    "    Returns:\n",
    "        float: Total distance metric to minimize.\n",
    "    \"\"\"\n",
    "    num_nodes = len(G.nodes())\n",
    "    rotation_matrices = params.reshape(num_nodes, 3, 3)\n",
    "    total_distance = 0.0\n",
    "\n",
    "    for (i, j) in sorted_edges:\n",
    "        R_i = reorthogonalize_matrix(rotation_matrices[i])\n",
    "        R_j = reorthogonalize_matrix(rotation_matrices[j])\n",
    "\n",
    "        com_i = G.nodes[sorted_nodes[i]]['ccoords']\n",
    "        com_j = G.nodes[sorted_nodes[j]]['ccoords']\n",
    "\n",
    "        # Rotate positions around their mass center\n",
    "        rotated_i_positions = np.dot(static_atom_positions[i][:,1:] - com_i, R_i.T) + com_i\n",
    "        rotated_j_positions = np.dot(static_atom_positions[j][:,1:] - com_j, R_j.T) + com_j\n",
    "\n",
    "\n",
    "        for idx_i in range(len(rotated_i_positions)):\n",
    "            for idx_j in range(len(rotated_j_positions)):\n",
    "                dist = np.linalg.norm(rotated_i_positions[idx_i] - rotated_j_positions[idx_j])\n",
    "                total_distance += dist ** 2\n",
    "\n",
    "    return total_distance\n",
    "\n",
    "\n",
    "def optimize_rotations(num_nodes, sorted_edges,atom_positions):\n",
    "    \"\"\"\n",
    "    Optimize rotations for all nodes in the graph.\n",
    "\n",
    "    Parameters:\n",
    "        G (networkx.Graph): Graph structure with edges between nodes.\n",
    "        atom_positions (dict): Positions of X atoms for each node.\n",
    "\n",
    "    Returns:\n",
    "        list: Optimized rotation matrices for all nodes.\n",
    "    \"\"\"\n",
    "    initial_rotations = np.tile(np.eye(3), (num_nodes, 1)).flatten()\n",
    "    static_atom_positions = atom_positions.copy()\n",
    "    # Precompute edge-specific pairings\n",
    "    #edge_pairings = find_edge_pairings(sorted_edges, atom_positions)\n",
    "\n",
    "    result = minimize(\n",
    "        objective_function,\n",
    "        initial_rotations,\n",
    "        args=(G, static_atom_positions, sorted_edges),\n",
    "        method=\"L-BFGS-B\",\n",
    "        options={\"maxiter\": 5000, \"disp\": True } \n",
    "    )\n",
    "\n",
    "    \n",
    "\n",
    "    optimized_rotations = result.x.reshape(num_nodes, 3, 3)\n",
    "    optimized_rotations = [reorthogonalize_matrix(R) for R in optimized_rotations]\n",
    "    \n",
    "   ## # Print the optimized pairings after optimization\n",
    "   ## print(\"Optimized Pairings (after optimization):\")\n",
    "   ## for (i, j), pairs in edge_pairings.items():\n",
    "   ##     print(f\"Node {i} and Node {j}:\")\n",
    "   ##     for idx_i, idx_j in pairs:\n",
    "   ##         print(f\"  node{i}_{idx_i} -- node{j}_{idx_j}\")\n",
    "   ## print()\n",
    "\n",
    "    return optimized_rotations,static_atom_positions\n",
    "\n",
    "def apply_rotations_to_atom_positions(optimized_rotations, G, atom_positions):\n",
    "    \"\"\"\n",
    "    Apply the optimized rotation matrices to the atom positions.\n",
    "\n",
    "    Parameters:\n",
    "        optimized_rotations (list): Optimized rotation matrices for each node.\n",
    "        G (networkx.Graph): Graph structure.\n",
    "        atom_positions (dict): Original positions of X atoms for each node.\n",
    "\n",
    "    Returns:\n",
    "        dict: Rotated positions for each node.\n",
    "    \"\"\"\n",
    "    rotated_positions = {}\n",
    "\n",
    "    for i, node in enumerate(sorted_nodes):\n",
    "        #if node type is V\n",
    "       # if 'DV' in G.nodes[node]['type']:\n",
    "            #continue\n",
    "        print(sorted_nodes[i])\n",
    "        R = optimized_rotations[i]\n",
    "        \n",
    "        original_positions = atom_positions[i]\n",
    "    \n",
    "        com = G.nodes[node]['ccoords']\n",
    "\n",
    "        # Translate, rotate, and translate back to preserve the mass center\n",
    "        translated_positions = original_positions - com\n",
    "        rotated_translated_positions = np.dot(translated_positions, R.T)\n",
    "        rotated_positions[node] = rotated_translated_positions + com\n",
    "\n",
    "    return rotated_positions\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def save_xyz(filename, rotated_positions_dict,sorted_nodes):\n",
    "    \"\"\"\n",
    "    Save the rotated positions to an XYZ file for visualization.\n",
    "    \"\"\"\n",
    "    with open(filename, \"w\") as file:\n",
    "        num_atoms = sum(len(positions) for positions in rotated_positions_dict.values())\n",
    "        file.write(f\"{num_atoms}\\n\")\n",
    "        file.write(\"Optimized structure\\n\")\n",
    "\n",
    "        for node, positions in rotated_positions_dict.items():\n",
    "            for pos in positions:\n",
    "                file.write(f\"X{node}   {pos[0]:.8f} {pos[1]:.8f} {pos[2]:.8f}\\n\")\n",
    "\n",
    "\n",
    "\n",
    "# Optimize rotations\n",
    "num_nodes = G.number_of_nodes()\n",
    "\n",
    "###3D free rotation\n",
    "#optimized_rotations,static_xxxx_positions = optimize_rotations(num_nodes,sorted_edges, xxxx_positions_dict)\n",
    "\n",
    "\n",
    "###2D axis rotation\n",
    "axis = pillar_vec  # Rotate around x-axis\n",
    "optimized_rotations = axis_optimize_rotations(axis, num_nodes, sorted_edges, xxxx_positions_dict)\n",
    "\n",
    "\n",
    "\n",
    "# Apply rotations\n",
    "rotated_node_positions = apply_rotations_to_atom_positions(optimized_rotations, G, chain_node_positions_dict)\n",
    "\n",
    "# Save results to XYZ\n",
    "save_xyz(\"optimized_nodesstructure.xyz\", rotated_node_positions,sorted_nodes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def locate_min_idx(a_array):\n",
    "    print(a_array)\n",
    "    row_idx = np.argmin(a_array)\n",
    "    print(row_idx)\n",
    "    print(a_array.shape)\n",
    "    col_idx = np.argmin(a_array[row_idx])\n",
    "    return row_idx,col_idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def locate_min_idx(a_array):\n",
    "    print(a_array,np.min(a_array))\n",
    "    idx = np.argmin(a_array)\n",
    "    row_idx = idx // a_array.shape[1]\n",
    "    col_idx = idx % a_array.shape[1]\n",
    "    return row_idx,col_idx\n",
    "\n",
    "def find_optimal_pairings(node_i_positions, node_j_positions):\n",
    "    \"\"\"\n",
    "    Find the optimal one-to-one pairing between atoms in two nodes using the Hungarian algorithm.\n",
    "    \"\"\"\n",
    "    num_i, num_j = len(node_i_positions), len(node_j_positions)\n",
    "    cost_matrix = np.zeros((num_i, num_j))\n",
    "    for i in range(num_i):\n",
    "        for j in range(num_j):\n",
    "            cost_matrix[i, j] = np.linalg.norm(node_i_positions[i,1:] - node_j_positions[j,1:])\n",
    "\n",
    "    #row_ind, col_ind = linear_sum_assignment(cost_matrix)\n",
    "    print(cost_matrix.shape)\n",
    "    row_ind, col_ind = locate_min_idx(cost_matrix)\n",
    "    print(row_ind,col_ind,cost_matrix)\n",
    "  \n",
    "\n",
    "    return [row_ind,col_ind]\n",
    "\n",
    "#after test, we find that we cannot get an exclusive pair, because of the bad initial guess\n",
    "##def update_pairs(pairs,atom_positions,i,j):\n",
    "##    nodeA_idx_set = atom_positions[i][:,0]\n",
    "##    nodeB_idx_set = atom_positions[j][:,0]\n",
    "##    correct_idx_pair =[]\n",
    "##    for k in range(len(pairs)):\n",
    "##        idx_A,idx_B = nodeA_idx_set[pairs[k][0]],nodeB_idx_set[pairs[k][1]]\n",
    "##        correct_idx_pair.append((idx_A,idx_B))\n",
    "##    return correct_idx_pair\n",
    "\n",
    "def find_edge_pairings(sorted_edges, atom_positions):\n",
    "    \"\"\"\n",
    "    Identify optimal pairings for each edge in the graph.\n",
    "\n",
    "    Parameters:\n",
    "        G (networkx.Graph): Graph structure with edges between nodes.\n",
    "        atom_positions (dict): Positions of X atoms for each node.\n",
    "\n",
    "    Returns:\n",
    "        dict: Mapping of edges to optimal atom pairs.\n",
    "              Example: {(0, 1): [(0, 3), (1, 2)], ...}\n",
    "    \"\"\"\n",
    "\n",
    "    edge_pairings = {}\n",
    "    \n",
    "    for i, j in sorted_edges:\n",
    "        node_i_positions = atom_positions[i] #[index,x,y,z]\n",
    "        node_j_positions = atom_positions[j] #[index,x,y,z]\n",
    "\n",
    "\n",
    "        # Find optimal pairings for this edge\n",
    "        \n",
    "        pairs = find_optimal_pairings(node_i_positions, node_j_positions)\n",
    "        print(sorted_nodes[i],sorted_nodes[j],pairs)\n",
    "        edge_pairings[(i, j)] = pairs #update_pairs(pairs,atom_positions,i,j)\n",
    "        #idx_0,idx_1 = pairs[0]\n",
    "        #x_idx_0 = atom_positions[i][idx_0][0]\n",
    "        #x_idx_1 = atom_positions[j][idx_1][0]\n",
    " #\n",
    "        #edge_pairings[(i, j)] = update_pairs(pairs,atom_positions,i,j) #but only first pair match\n",
    "        #atom_positions[i] = np.delete(atom_positions[i], idx_0, axis=0)\n",
    "        #atom_positions[j] = np.delete(atom_positions[j], idx_1, axis=0)\n",
    "\n",
    "    return edge_pairings\n",
    "\n",
    "def apply_rotations_to_xxxx_positions(optimized_rotations, G, xxxx_positions_dict):\n",
    "    \"\"\"\n",
    "    Apply the optimized rotation matrices to the atom positions.\n",
    "\n",
    "    Parameters:\n",
    "        optimized_rotations (list): Optimized rotation matrices for each node.\n",
    "        G (networkx.Graph): Graph structure.\n",
    "        atom_positions (dict): Original positions of X atoms for each node.\n",
    "\n",
    "    Returns:\n",
    "        dict: Rotated positions for each node.\n",
    "    \"\"\"\n",
    "    rotated_positions = {}\n",
    "\n",
    "    for i, node in enumerate(sorted_nodes):\n",
    "        #if node type is V\n",
    "        #if 'DV' in G.nodes[node]['type']:\n",
    "            #continue\n",
    "        R = optimized_rotations[i]\n",
    "\n",
    "        \n",
    "        original_positions = xxxx_positions_dict[i][:,1:]\n",
    "        com = G.nodes[node]['ccoords']\n",
    "\n",
    "        # Translate, rotate, and translate back to preserve the mass center\n",
    "        translated_positions = original_positions - com\n",
    "        rotated_translated_positions = np.dot(translated_positions, R.T)\n",
    "        xxxx_positions_dict[i][:,1:] = rotated_translated_positions + com\n",
    "    edge_pair=find_edge_pairings(sorted_edges, xxxx_positions_dict)\n",
    "    print(\"Optimized Pairings (after optimization):\")\n",
    "    \n",
    "    optimized_pair = {}\n",
    "\n",
    "    for (i, j), pair in edge_pair.items():\n",
    "        print(f\"Node {sorted_nodes[i]} and Node {sorted_nodes[j]}:\")\n",
    "        idx_i, idx_j = pair\n",
    "        print(f\"  node{sorted_nodes[i]}_{int(idx_i)} -- node{sorted_nodes[j]}_{int(idx_j)}\")\n",
    "        optimized_pair[sorted_nodes[i],sorted_nodes[j]] = (int(idx_i),int(idx_j))\n",
    " \n",
    "\n",
    "\n",
    "    return rotated_positions,optimized_pair\n",
    "\n",
    "_,optimized_pair=apply_rotations_to_xxxx_positions(optimized_rotations, G, xxxx_positions_dict)\n",
    "optimized_pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test for scale \n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "def unit_cell_to_cartesian_matrix(aL,bL,cL,alpha,beta,gamma):\n",
    "    pi = np.pi\n",
    "    \"\"\"Convert unit cell parameters to a Cartesian transformation matrix.\"\"\"\n",
    "    aL,bL,cL,alpha,beta,gamma = list(map(float, (aL,bL,cL,alpha,beta,gamma)))\n",
    "    ax = aL\n",
    "    ay = 0.0\n",
    "    az = 0.0\n",
    "    bx = bL * np.cos(gamma * pi / 180.0)\n",
    "    by = bL * np.sin(gamma * pi / 180.0)\n",
    "    bz = 0.0\n",
    "    cx = cL * np.cos(beta * pi / 180.0)\n",
    "    cy = (cL * bL * np.cos(alpha * pi /180.0) - bx * cx) / by\n",
    "    cz = (cL ** 2.0 - cx ** 2.0 - cy ** 2.0) ** 0.5\n",
    "    unit_cell = np.asarray([[ax,ay,az],[bx,by,bz],[cx,cy,cz]]).T\n",
    "    return unit_cell\n",
    "\n",
    "def fractional_to_cartesian(fractional_coords, T):\n",
    "    \"\"\"Convert fractional coordinates to Cartesian using the transformation matrix.\"\"\"\n",
    "    return np.dot(fractional_coords, T.T)\n",
    "\n",
    "def cartesian_to_fractional(cartesian_coords, unit_cell_inv):\n",
    "    \"\"\"Convert Cartesian coordinates to fractional coordinates using the inverse transformation matrix.\"\"\"\n",
    "    return np.dot(cartesian_coords, unit_cell_inv.T)\n",
    "\n",
    "def objective_function(params, old_cell_params, old_cartesian_coords, new_cartesian_coords):\n",
    "    a_new, b_new, c_new, alpha_new, beta_new, gamma_new = params\n",
    "    a_old, b_old, c_old, alpha_old, beta_old, gamma_old = old_cell_params\n",
    "\n",
    "    # Compute transformation matrix for the old unit cell\n",
    "    T_old = unit_cell_to_cartesian_matrix(a_old, b_old, c_old, alpha_old, beta_old, gamma_old)\n",
    "    T_old_inv= np.linalg.inv(T_old)\n",
    "    #backup\n",
    "    old_fractional_coords = cartesian_to_fractional(old_cartesian_coords, T_old_inv)\n",
    "\n",
    "    # Compute transformation matrix for the new unit cell\n",
    "    T_new = unit_cell_to_cartesian_matrix(a_new, b_new, c_new, alpha_new, beta_new, gamma_new)\n",
    "    T_new_inv= np.linalg.inv(T_new)\n",
    "\n",
    "    # Convert the new Cartesian coordinates to fractional coordinate using the old unit cell\n",
    "    fractional_coords_new = cartesian_to_fractional(new_cartesian_coords, T_new_inv)\n",
    "\n",
    "    # Minimize the difference between the calculated new Cartesian coordinates and the provided new Cartesian coordinates\n",
    "    return np.sum(np.linalg.norm(fractional_coords_new - old_fractional_coords, axis=1)**2)\n",
    "\n",
    "# Example usage\n",
    "# Old cell parameters (example values)\n",
    "old_cell_params = [a, b, c, ang_alpha, ang_beta, ang_gamma]  # [a, b, c, alpha, beta, gamma]\n",
    "\n",
    "# Old Cartesian coordinates of points (example values)\n",
    "old_cartesian_coords = np.array([\n",
    "    [0.0, 0.0, 0.0],    # Point 1\n",
    "    [2.5, 3.0, 3.5],    # Point 2\n",
    "    [1.25, 1.5, 5.25],  # Point 3\n",
    "    [0.5, 2.4, 4.9]     # Point 4\n",
    "])\n",
    "\n",
    "\n",
    "# New Cartesian coordinates of the same points (example values)\n",
    "new_cartesian_coords = np.array([\n",
    "    [0.0, 0.0, 0.0],    # Point 1\n",
    "    [5, 6, 7],    # Point 2\n",
    "    [2.5, 3, 10.5],    # Point 3\n",
    "    [1, 4.8, 9.8]     # Point 4\n",
    "])\n",
    "\n",
    "# Initial guess for new unit cell parameters (e.g., slightly modified cell)\n",
    "initial_params = [4.5, 4.5, 4.5, 90.0, 90.0, 90.0]\n",
    "\n",
    "# Bounds: a, b, c > 0; angles [0, 180]\n",
    "bounds = [(0, None)] * 3 + [(20, 180)] * 3\n",
    "\n",
    "# Optimize using L-BFGS-B to minimize the objective function\n",
    "result = minimize(\n",
    "    objective_function,\n",
    "    x0=initial_params,\n",
    "    args=(old_cell_params, old_cartesian_coords, new_cartesian_coords),\n",
    "    method='L-BFGS-B',\n",
    "    bounds=bounds\n",
    ")\n",
    "\n",
    "# Extract optimized parameters\n",
    "optimized_params = np.round(result.x,5)\n",
    "print(\"Optimized New Cell Parameters:\", optimized_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vlx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
