{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "from tests.MOF_builder.functions.ciftemplate2graph import ct2g,node_vecs\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import os\n",
    "import veloxchem as vlx\n",
    "import re\n",
    "from numpy.linalg import norm\n",
    "from tests.MOF_builder.functions.bbcif_properties import bb2array,X_vecs,selected_type_vecs\n",
    "from tests.MOF_builder.functions.place_bbs import superimpose,mag_superimpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "center is two points\n",
      "[9, 14]\n",
      "ditopic linker: center are two points\n",
      "find connected X in edge:   24\n",
      "find connected X in edge:   39\n",
      "edges/diedge.cif is writen\n",
      "center_frag: 46 [18, 33]\n"
     ]
    }
   ],
   "source": [
    "from src.MOF_builder.functions.frag_recognizer import process_linker_molecule\n",
    "linker_file = 'ndi.xyz'\n",
    "molecule = vlx.Molecule.read_xyz_file(linker_file)\n",
    "linker_topic =2\n",
    "center_frag_nodes_num,center_Xs,single_frag_nodes_num,frag_Xs= process_linker_molecule(molecule,linker_topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nEr1     Er     0.8416   0.75   0.1586\\nEr2     Er     0.6584   0.75   0.3414\\nEr3     Er     0.8416   0.25   0.8414\\nEr4     Er     0.6584   0.25   0.6586\\nV5     V     0.5   0.5   0.5\\nV6     V     0.5   0.0   0.5\\nEr7     Er     0.1584   0.25   0.8414\\nEr8     Er     0.3416   0.25   0.6586\\nEr9     Er     0.1584   0.75   0.1586\\nEr10     Er     0.3416   0.75   0.3414\\nV11     V     0.0   0.0   0.0\\nV12     V     0.0   0.5   0.0\\nloop_\\n_geom_bond_atom_site_label_1\\n_geom_bond_atom_site_label_2\\n_geom_bond_distance\\n_geom_bond_site_symmetry_2\\n_ccdc_geom_bond_type\\nEr1     Er2    10.0   .     S\\nEr1     V11    10.0   1_665     S\\nEr1     V12    10.0   1_655     S\\nEr2     V5    10.0   .     S\\nEr2     V6    10.0   1_565     S\\nEr3     Er4    10.0   .     S\\nEr3     V12    10.0   1_656     S\\nEr3     V11    10.0   1_656     S\\nEr4     V5    10.0   .     S\\nEr4     V6    10.0   .     S\\nV5     V6    10.0   .     S\\nV5     V6    10.0   1_565     S\\nV5     Er8    10.0   .     S\\nV5     Er10    10.0   .     S\\nV6     V5    10.0   1_545     S\\nV6     Er8    10.0   .     S\\nV6     Er2    10.0   1_545     S\\nV6     Er10    10.0   1_545     S\\nEr7     Er8    10.0   .     S\\nEr7     V11    10.0   1_556     S\\nEr7     V12    10.0   1_556     S\\nEr9     Er10    10.0   .     S\\nEr9     V11    10.0   1_565     S\\nEr9     V12    10.0   .     S\\nEr10     V6    10.0   1_565     S\\nV11     V12    10.0   1_545     S\\nV11     Er1    10.0   1_445     S\\nV11     V12    10.0   .     S\\nV11     Er3    10.0   1_454     S\\nV11     Er9    10.0   1_545     S\\nV11     Er7    10.0   1_554     S\\nV12     V11    10.0   1_565     S\\nV12     Er1    10.0   1_455     S\\nV12     Er3    10.0   1_454     S\\nV12     Er7    10.0   1_554     S\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display edges of the graph\n",
    "\n",
    "\n",
    "'''\n",
    "Er1     Er     0.8416   0.75   0.1586\n",
    "Er2     Er     0.6584   0.75   0.3414\n",
    "Er3     Er     0.8416   0.25   0.8414\n",
    "Er4     Er     0.6584   0.25   0.6586\n",
    "V5     V     0.5   0.5   0.5\n",
    "V6     V     0.5   0.0   0.5\n",
    "Er7     Er     0.1584   0.25   0.8414\n",
    "Er8     Er     0.3416   0.25   0.6586\n",
    "Er9     Er     0.1584   0.75   0.1586\n",
    "Er10     Er     0.3416   0.75   0.3414\n",
    "V11     V     0.0   0.0   0.0\n",
    "V12     V     0.0   0.5   0.0\n",
    "loop_\n",
    "_geom_bond_atom_site_label_1\n",
    "_geom_bond_atom_site_label_2\n",
    "_geom_bond_distance\n",
    "_geom_bond_site_symmetry_2\n",
    "_ccdc_geom_bond_type\n",
    "Er1     Er2    10.0   .     S\n",
    "Er1     V11    10.0   1_665     S\n",
    "Er1     V12    10.0   1_655     S\n",
    "Er2     V5    10.0   .     S\n",
    "Er2     V6    10.0   1_565     S\n",
    "Er3     Er4    10.0   .     S\n",
    "Er3     V12    10.0   1_656     S\n",
    "Er3     V11    10.0   1_656     S\n",
    "Er4     V5    10.0   .     S\n",
    "Er4     V6    10.0   .     S\n",
    "V5     V6    10.0   .     S\n",
    "V5     V6    10.0   1_565     S\n",
    "V5     Er8    10.0   .     S\n",
    "V5     Er10    10.0   .     S\n",
    "V6     V5    10.0   1_545     S\n",
    "V6     Er8    10.0   .     S\n",
    "V6     Er2    10.0   1_545     S\n",
    "V6     Er10    10.0   1_545     S\n",
    "Er7     Er8    10.0   .     S\n",
    "Er7     V11    10.0   1_556     S\n",
    "Er7     V12    10.0   1_556     S\n",
    "Er9     Er10    10.0   .     S\n",
    "Er9     V11    10.0   1_565     S\n",
    "Er9     V12    10.0   .     S\n",
    "Er10     V6    10.0   1_565     S\n",
    "V11     V12    10.0   1_545     S\n",
    "V11     Er1    10.0   1_445     S\n",
    "V11     V12    10.0   .     S\n",
    "V11     Er3    10.0   1_454     S\n",
    "V11     Er9    10.0   1_545     S\n",
    "V11     Er7    10.0   1_554     S\n",
    "V12     V11    10.0   1_565     S\n",
    "V12     Er1    10.0   1_455     S\n",
    "V12     Er3    10.0   1_454     S\n",
    "V12     Er7    10.0   1_554     S\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1), (2, 3)]\n",
      "15.754259612561926 linker_length\n"
     ]
    }
   ],
   "source": [
    "#pillar stack structure:\n",
    "#regarding chain_node cif file:\n",
    "    #find the pillar direction vector which is defined by the Al-Al vectors in chain_node cif file \n",
    "    #find the pair of x vectors, which are vertical to the pillar direction vector in chain_node cif file, could be more than one pairs\n",
    "    #find the Al-Al length, read from the cif file\n",
    "#regarding the linker cif file:\n",
    "    #find the length of the linker which should be the maximum length of X vectors in the linker cif file\n",
    "\n",
    "#regarding the template cif file:\n",
    "    #find the pillar direction which should be along the pure V-V direction (no Er node between) in the template cif file, \n",
    "    #find the edge vector in the template cif file, which should be Er-Er edge\n",
    "    #find the length of the edge vector in the template cif file\n",
    "    #fix one direction of the box, which should be parallel to the pilalar direction\n",
    "\n",
    "#the unit_cell of the template cif file should be scaled to fit the length of the linker, and the box_vector which along pillar direction should be fixed\n",
    "#when we want to place the node in the box, we should use a pair of x vectors which targets the connected V through the edge vector in the template cif file and the pillar direction vector, we use superimpose function to rotate and place the node at the right position\n",
    "#when we want to place the edge in the box, we should consider all of the x vectors placed in box and find the connected connected x vectors in two sidde of the Er-Er edge, then we use superimpose function to rotate and place the edge at the right position \n",
    "from tests.MOF_builder.functions.bbcif_properties import bb2array,selected_type_vecs,calc_edge_len\n",
    "from tests.MOF_builder.functions.place_bbs import superimpose\n",
    "\n",
    "chain_node_cif = '1Alchain.cif'\n",
    "template_cif = 'chain_rna.cif'\n",
    "linker_cif = 'edges/diedge.cif'\n",
    "#chain node\n",
    "Al_vecs = selected_type_vecs(chain_node_cif,'.', 'Al',False)\n",
    "chain_node_arr = bb2array(chain_node_cif,'.')\n",
    "\n",
    "chain_node_arr = bb2array(chain_node_cif,'.')\n",
    "metal_cvec = Al_vecs[0]-Al_vecs[1]\n",
    "node_pillar_cvec = metal_cvec/norm(metal_cvec) \n",
    "\n",
    "x_vecs = selected_type_vecs(chain_node_cif,'.','X',False)\n",
    "\n",
    "\n",
    "#find the x vectors which are vertical to the pillar direction\n",
    "xx_pairs = []\n",
    "for i in range(0,len(x_vecs)):\n",
    "    for j in range(i+1,len(x_vecs)):\n",
    "        xx_vec = x_vecs[i]-x_vecs[j]\n",
    "        xx_vec = xx_vec/norm(xx_vec)\n",
    "        if np.dot(xx_vec,metal_cvec) < 1e-3:\n",
    "            xx_pairs.append((i,j))\n",
    "print(xx_pairs)\n",
    "#linker\n",
    "linker_x_vecs = selected_type_vecs(linker_cif,'.','X',False)\n",
    "#ditopic linker only has two x vectors\n",
    "linker_length = calc_edge_len(linker_cif,'.') #length of the edge should be x-x length in linker cif file, unit angstrom\n",
    "print(linker_length,'linker_length')\n",
    "\n",
    "#template\n",
    "gen = ct2g('chain_rna.cif', 'tests/templates')\n",
    "net = next(gen)\n",
    "TG, start, unit_cell, TVT, TET, TNAME, a, b, c, ang_alpha, ang_beta, ang_gamma, max_le, catenation = net\n",
    "#ditopic linker should be connected to two V nodes directly \n",
    "#find path between two nodes which starts from V node to V node passing through Er nodes\n",
    "Vnodes = [n for n in TG.nodes() if n.startswith('V')]\n",
    "Ernodes = [n for n in TG.nodes() if n.startswith('Er')]\n",
    "\n",
    "valid_paths = []\n",
    "Vnodes = [n for n in TG.nodes() if n.startswith('V')]\n",
    "for i in range(0, len(Vnodes)):\n",
    "    for j in range(i+1, len(Vnodes)):\n",
    "        source=Vnodes[i]\n",
    "        target=Vnodes[j]\n",
    "        path = nx.shortest_path(TG, source,target)\n",
    "        if len(path) > 2:\n",
    "            #if only two V nodes are there in the path, then it is a valid path\n",
    "            if all([n.startswith('Er') for n in path[1:-1]]):\n",
    "                #print(source, target, path)\n",
    "                valid_paths.append(path)\n",
    "\n",
    "NG = nx.Graph()\n",
    "edges_info=TG.edges(data=True)\n",
    "count = 1\n",
    "le=0\n",
    "pillars_cvecs = []\n",
    "pillars_fvecs = []\n",
    "edge_cvecs = []\n",
    "edge_fvecs = []\n",
    "for edge in edges_info:\n",
    "    #node1,node2=edge[0],edge[1]\n",
    "    edge_type=edge[2]['type']\n",
    "    edge_label=edge[2]['label']\n",
    "    edge_ccoord=edge[2]['ccoords']\n",
    "    edge_fcoord=edge[2]['fcoords']\n",
    "    edge_length=edge[2]['length']\n",
    "    edge_index=edge[2]['index']\n",
    "    edge_pd = edge[2]['pd']\n",
    "    node1,node2 = edge_pd\n",
    " \n",
    "    if edge_type[0]==edge_type[1]:\n",
    "        #V-V find the pillar direction which should be along the pure V-V direction (no Er node between) in the template cif file\n",
    "        if edge_type[0]=='V':# chain of metal nodes\n",
    "            #print(node1,node2,edge_type,edge_fcoord,edge_length,edge_index,edge_pd)\n",
    "            name = node1+node2+'_'+str(count)\n",
    "            pillars_cvecs.append(TG.nodes[node1]['ccoords']-TG.nodes[node2]['ccoords'])\n",
    "            pillars_fvecs.append(TG.nodes[node1]['fcoords']-TG.nodes[node2]['fcoords'])\n",
    "            NG.add_node(name, label = (node1,node2),type=edge_type, index=edge_index, ccoords=edge_ccoord, fcoords=edge_fcoord, cn=[], cifname=[])\n",
    "            count+=1\n",
    "        #Er-Er find the edge vector in the template cif file, which should be Er-Er edge\n",
    "        else:\n",
    "            le = max(edge_length,le) #find the length of the edge vector in the template cif file\n",
    "            edge_cvecs.append(TG.nodes[node1]['ccoords']-TG.nodes[node2]['ccoords'])\n",
    "            edge_fvecs.append(TG.nodes[node1]['fcoords']-TG.nodes[node2]['fcoords'])\n",
    "            pass\n",
    "            #edge direction \n",
    "            #print(node1,node2,edge_type,edge_fcoord,edge_length,edge_index,edge_pd)\n",
    "            #get evecs\n",
    "\n",
    "    else:\n",
    "        #ignore Er-V\n",
    "        #print(node1,node2,edge_type)\n",
    "        pass\n",
    "\n",
    "#in NG any VV node has 'V5' should be connected to antoher VV node with 'V11' and 'V12'\n",
    "for path in valid_paths:\n",
    "    source = path[0]\n",
    "    target = path[-1]\n",
    "    #in NG any VV node has source should be connected to antoher VV node with target\n",
    "    vv_source_nodes = [node for node in NG.nodes() if source in NG.nodes[node]['label']]\n",
    "    vv_target_nodes = [node for node in NG.nodes() if target in NG.nodes[node]['label']]\n",
    "    #connect any source node to any target node\n",
    "\n",
    "\n",
    "#find the pillar direction which should be along the pure V-V direction (no Er node between) in the template cif file\n",
    "count = 1\n",
    "edges_cvecs=[]\n",
    "edges_fvecs=[]\n",
    "for vv_source_node in vv_source_nodes:\n",
    "    for vv_target_node in vv_target_nodes:\n",
    "        fcoord = (NG.nodes[vv_source_node]['fcoords'],NG.nodes[vv_target_node]['fcoords'])\n",
    "        ccoord = (NG.nodes[vv_source_node]['ccoords'],NG.nodes[vv_target_node]['ccoords'])\n",
    "        edges_cvecs.append(NG.nodes[vv_target_node]['ccoords']- NG.nodes[vv_source_node]['ccoords'])\n",
    "        edges_fvecs.append(NG.nodes[vv_target_node]['fcoords']- NG.nodes[vv_source_node]['fcoords'])\n",
    "        lbl = [0,0,0]\n",
    "        NG.add_edge(vv_source_node,vv_target_node,key=(count,lbl[0],lbl[1],lbl[2]), label=lbl , length=le, fcoords=fcoord, ccoords=ccoord, index=count, pd=(vv_source_node,vv_target_node))\n",
    "        count+=1\n",
    "        \n",
    "\n",
    "\n",
    "#fix one direction of the box, which should be parallel to the pilalar direction\n",
    "\n",
    "\n",
    "\n",
    "#the unit_cell of the template cif file should be scaled to fit the length of the linker, and the box_vector which along pillar direction should be fixed\n",
    "\n",
    "\n",
    "#find the pillar direction which should be along the pure V-V direction (no Er node between) in the template cif file\n",
    "\n",
    "\n",
    "#find the pillar direction which should be along the pure V-V direction (no Er node between) in the template cif file\n",
    "\n",
    "\n",
    "cns = []\n",
    "for n in NG.nodes():\n",
    "    cn = NG.degree(n) #Gets the degree (number of connections) of node n in the main graph G.\n",
    "    ty = re.sub('[0-9]','',n) #Removes numeric characters from the node identifier to get its type.\n",
    "    cns.append((cn, ty))\n",
    "TVT = set(cns)\n",
    "\n",
    "\n",
    "\n",
    "e_types = []\n",
    "for e in NG.edges():\n",
    "    e0 = e[0]\n",
    "    e1 = e[1]\n",
    "    l = sorted([re.sub('[^a-zA-Z]','',e0),re.sub('[^a-zA-Z]','',e1)]) #Sorts and strips non-alphabetic characters from node identifiers to determine the edge type.\n",
    "    e_types.append((l[0],l[1]))\n",
    "TET = set(e_types)\n",
    "\n",
    "\n",
    "TVT = sorted(TVT, key=lambda x:x[0], reverse=True) # sort node with connected degree, the first one is the highest(full)-coordinated node\n",
    "TET = sorted(TET, reverse=True) #sort node_pair by the node_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fix one direction of the box, which should be parallel to the pilalar direction\n",
    "\n",
    "#rotate the node to pillar direction and put all nodes into the cartesian coordinate \n",
    "\n",
    "chain_node_coords = np.asarray([i[1] for i in chain_node_arr])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pillar_vec in template: [0. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "pillar_vecs =[]\n",
    "for vec in pillars_cvecs:\n",
    "    norm_vec = np.abs(vec/norm(vec))\n",
    "    pillar_vecs.append(np.round(norm_vec,5))\n",
    "\n",
    "if len(np.unique(pillar_vecs,axis=0)) >1:\n",
    "    raise ValueError ('cannot find pillar vector in template net')\n",
    "else:\n",
    "    pillar_vec = np.unique(pillar_vecs,axis=0)\n",
    "    pillar_vec = pillar_vec.flatten()\n",
    "    print('pillar_vec in template:', pillar_vec)\n",
    "\n",
    "beginning_point = [0.0,0.0,0.0]\n",
    "pillar_vec,node_pillar_cvec\n",
    "rms,rot,tran = superimpose([beginning_point,node_pillar_cvec],[beginning_point,pillar_vec])\n",
    "\n",
    "pillar_oriented_nodexvec=np.dot(np.asarray(x_vecs),rot)\n",
    "pillar_oriented_nodecoords = np.dot(chain_node_coords,rot)\n",
    "nodexxxx = []\n",
    "chain_node_positions = []\n",
    "for n in NG.nodes():\n",
    "    nodexxxx.append(NG.nodes[n]['ccoords']+pillar_oriented_nodexvec)\n",
    "    chain_node_positions.append(NG.nodes[n]['ccoords']+pillar_oriented_nodecoords)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tests.MOF_builder.functions.bbcif_properties import bb2array,X_vecs,selected_type_vecs\n",
    "bb2array('1Alchain.cif', '.')\n",
    "xvecs = X_vecs('1Alchain.cif', '.',False)\n",
    "metal_vecs = selected_type_vecs('1Alchain.cif', '.','Al',False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_node_vecs2edges(nodes_dir,TG, unit_cell, SYM_TOL, template_name):\n",
    "\n",
    "\n",
    "\t'''\n",
    "\tThe assign_node_vecs2edges function is designed to assign node vectors to edges in a graph TG, \n",
    "\tusing unit cell transformations and checking for deviations. \n",
    "\n",
    "\tTG: A networkx graph object representing the target graph.\n",
    "\tunit_cell: The unit cell matrix used for transformation.\n",
    "\tSYM_TOL: Symmetry tolerance, not explicitly used in the function but possibly relevant for other parts of the process.\n",
    "\ttemplate_name: The name of the template, used in warning messages.\n",
    "\n",
    "\tReturn the dictionary containing edge assignments for each node.\n",
    "\t'''\n",
    "\t#Initialize Edge Assignment Dictionary\n",
    "\tedge_assign_dict = dict((k,{}) for k in TG.nodes())\n",
    "\t#Loop Through Nodes in the Graph\n",
    "\t##Loop through each node in the graph TG, extracting the node name and node dictionary.\n",
    "\t##cif: The name of the CIF file associated with the node.\n",
    "\n",
    "\tfor n in TG.nodes(data=True):\n",
    "\n",
    "\t\tname,ndict = n\n",
    "\t\tcif = ndict['cifname']\n",
    "\n",
    "\t\t#bbxlabels: Labels of the building block vectors.\n",
    "\t\t#nodlabels: Labels of the node vectors.\n",
    "\t\t#bbxvec: Vectors of the building block.\n",
    "\t\t#nodvec: Node vectors after unit cell transformation.\n",
    "\n",
    "\t\tbbxlabels = np.array([l[0] for l in X_vecs(cif,nodes_dir, True)])\n",
    "\t\tnodlabels = np.array([l[0] for l in node_vecs(n[0], TG, unit_cell, True)])\n",
    "\n",
    "\t\tbbxvec = X_vecs(cif, nodes_dir, False)\n",
    "\t\tnodvec = node_vecs(n[0], TG, unit_cell, False)\n",
    "\t\t\n",
    "\t\t#Superimpose Vectors\n",
    "\t\t##mag_superimpose: Function to superimpose vectors, returning RMSD, rotation, and translation.\n",
    "\t\t##aff_b: Apply the rotation and translation to the building block vectors.\n",
    "\t\t##laff_b: Concatenate labels with transformed building block vectors.\n",
    "\t\t##lnodvec: Concatenate labels with node vectors.\n",
    "\t\trmsd,rot,tran = mag_superimpose(bbxvec, nodvec)\n",
    "\t\taff_b = np.dot(bbxvec,rot) + tran\n",
    "\t\tlaff_b = np.c_[bbxlabels,aff_b]\n",
    "\t\tlnodvec = np.c_[nodlabels,nodvec]\n",
    "\t\t\n",
    "\t\t#Initialize Distance Matrix and Compute Distances\n",
    "\t\t#distance_matrix: Matrix to store distances between vectors.\n",
    "\t\t#For each pair of vectors, compute the normalized vectors \n",
    "\t\t# and the Euclidean distance between them, storing in the distance matrix.\n",
    "\t\tasd = []\n",
    "\t\tasd_append = asd.append\n",
    "\n",
    "\t\tdistance_matrix = np.zeros((len(laff_b),len(laff_b)))\n",
    "\t\tnrow = ncol = len(laff_b)\n",
    "\t\t\n",
    "\t\tfor i in range(nrow):\n",
    "\t\t\tfor j in range(ncol):\n",
    "\t\t\n",
    "\t\t\t\tv1 = laff_b[i]\n",
    "\t\t\t\tv1vec = np.array([float(q) for q in v1[1:]])\n",
    "\t\t\t\tv1vec /= norm(v1vec)\n",
    "\t\t\n",
    "\t\t\t\tv2 = lnodvec[j]\n",
    "\t\t\t\tv2vec = np.array([float(q) for q in v2[1:]])\n",
    "\t\t\t\tv2vec /= norm(v2vec)\n",
    "\t\t\n",
    "\t\t\t\tdist = np.linalg.norm(v1vec - v2vec)\n",
    "\t\t\t\tdistance_matrix[i,j] += dist\n",
    "\t\t\n",
    "\t\t#Sort Distances and Assign Edges\n",
    "\t\t#distances: List of distances sorted by distance.\n",
    "\t\t#For each distance, extract the vectors and check if the edge is already used.\n",
    "\t\t#If not used, append the assignment details to asd and add the edge to used_edges.\n",
    "\t\t#Raise a warning if the distance exceeds a certain threshold (0.60).\n",
    "\t\tdistances = []\n",
    "\t\tfor i in range(nrow):\n",
    "\t\t\tfor j in range(ncol):\n",
    "\t\t\t\tdistances.append((distance_matrix[i,j],i,j))\n",
    "\t\tdistances = sorted(distances, key=lambda x:x[0])\n",
    "\t\t\n",
    "\t\tused_edges = []\n",
    "\t\t\n",
    "\t\tfor dist in distances:\n",
    "\t\t\n",
    "\t\t\tv1 = laff_b[dist[1]]\n",
    "\t\t\tv1vec = np.array([float(q) for q in v1[1:]])\n",
    "\t\t\tmag = np.linalg.norm(v1vec)\n",
    "\t\t\n",
    "\t\t\tv2 = lnodvec[dist[2]]\n",
    "\t\t\tind = int(v2[0])\n",
    "\t\t\n",
    "\t\t\tedge_assign = ind\n",
    "\t\t\n",
    "\t\t\tif edge_assign not in used_edges:\n",
    "\n",
    "\t\t\t\tused_edges.append(edge_assign)\n",
    "\t\t\t\tasd_append([ind, v1[0], mag, v1vec, dist[0]])\n",
    "\t\t\t\t\n",
    "\t\t\t\tif dist[0] > 0.60:\n",
    "\t\t\t\t\tmessage = \"There is a nodular building block vector that deviates from its assigned edge by more large\\nthis may be fixed during scaling, but don't count on it!\\n\"\n",
    "\t\t\t\t\tmessage = message + \"the deviation is for \" + cif + \" assigned to \" + name + \" for template \" + template_name\n",
    "\t\t\t\t\twarnings.warn(message)\n",
    "\t\t\t\n",
    "\t\t\tif len(used_edges) == ncol:\n",
    "\t\t\t\tbreak\n",
    "\n",
    "\t\telad = dict((k[0], (k[1],k[2],k[3])) for k in asd)\n",
    "\t\tedge_assign_dict[name] = elad\n",
    "\t\t\t\t\t\n",
    "\treturn edge_assign_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nodes_dir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtests\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mMOF_builder\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctions\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mSBU_geometry\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SBU_coords\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtests\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mMOF_builder\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfiguration\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CONNECTION_SITE_BOND_LENGTH, SYMMETRY_TOL, FIX_UC, SCALING_ITERATIONS, PRE_SCALE, MIN_CELL_LENGTH, OPT_METHOD\n\u001b[0;32m----> 6\u001b[0m ea_dict \u001b[38;5;241m=\u001b[39m assign_node_vecs2edges(\u001b[43mnodes_dir\u001b[49m,TG, unit_cell, SYMMETRY_TOL, template)\n\u001b[1;32m      7\u001b[0m all_SBU_coords \u001b[38;5;241m=\u001b[39m SBU_coords(TG, ea_dict, CONNECTION_SITE_BOND_LENGTH)\n\u001b[1;32m      8\u001b[0m sc_a, sc_b, sc_c, sc_alpha, sc_beta, sc_gamma, sc_covar, Bstar_inv, max_length, callbackresults, ncra, ncca, scaling_data \u001b[38;5;241m=\u001b[39m scale(all_SBU_coords,a,b,c,ang_alpha,ang_beta,ang_gamma,max_le,num_vertices,Bstar,alpha,num_edges,FIX_UC,SCALING_ITERATIONS,PRE_SCALE,MIN_CELL_LENGTH,OPT_METHOD)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nodes_dir' is not defined"
     ]
    }
   ],
   "source": [
    "#test scale \n",
    "from tests.MOF_builder.functions.scale import scale\n",
    "from tests.MOF_builder.functions.vertex_edge_assign import assign_node_vecs2edges\n",
    "from tests.MOF_builder.functions.SBU_geometry import SBU_coords\n",
    "from tests.MOF_builder.configuration import CONNECTION_SITE_BOND_LENGTH, SYMMETRY_TOL, FIX_UC, SCALING_ITERATIONS, PRE_SCALE, MIN_CELL_LENGTH, OPT_METHOD\n",
    "ea_dict = assign_node_vecs2edges(nodes_dir,TG, unit_cell, SYMMETRY_TOL, template)\n",
    "all_SBU_coords = SBU_coords(TG, ea_dict, CONNECTION_SITE_BOND_LENGTH)\n",
    "sc_a, sc_b, sc_c, sc_alpha, sc_beta, sc_gamma, sc_covar, Bstar_inv, max_length, callbackresults, ncra, ncca, scaling_data = scale(all_SBU_coords,a,b,c,ang_alpha,ang_beta,ang_gamma,max_le,num_vertices,Bstar,alpha,num_edges,FIX_UC,SCALING_ITERATIONS,PRE_SCALE,MIN_CELL_LENGTH,OPT_METHOD)\n",
    "\t\t\t\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized New Cell Parameters: [63.86961 42.30462 77.11125 91.70537 93.78333 77.09491]\n"
     ]
    }
   ],
   "source": [
    "#test for scale \n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "def unit_cell_to_cartesian_matrix(aL,bL,cL,alpha,beta,gamma):\n",
    "    pi = np.pi\n",
    "    \"\"\"Convert unit cell parameters to a Cartesian transformation matrix.\"\"\"\n",
    "    aL,bL,cL,alpha,beta,gamma = list(map(float, (aL,bL,cL,alpha,beta,gamma)))\n",
    "    ax = aL\n",
    "    ay = 0.0\n",
    "    az = 0.0\n",
    "    bx = bL * np.cos(gamma * pi / 180.0)\n",
    "    by = bL * np.sin(gamma * pi / 180.0)\n",
    "    bz = 0.0\n",
    "    cx = cL * np.cos(beta * pi / 180.0)\n",
    "    cy = (cL * bL * np.cos(alpha * pi /180.0) - bx * cx) / by\n",
    "    cz = (cL ** 2.0 - cx ** 2.0 - cy ** 2.0) ** 0.5\n",
    "    unit_cell = np.asarray([[ax,ay,az],[bx,by,bz],[cx,cy,cz]]).T\n",
    "    return unit_cell\n",
    "\n",
    "def fractional_to_cartesian(fractional_coords, T):\n",
    "    \"\"\"Convert fractional coordinates to Cartesian using the transformation matrix.\"\"\"\n",
    "    return np.dot(fractional_coords, T.T)\n",
    "\n",
    "def cartesian_to_fractional(cartesian_coords, unit_cell_inv):\n",
    "    \"\"\"Convert Cartesian coordinates to fractional coordinates using the inverse transformation matrix.\"\"\"\n",
    "    return np.dot(cartesian_coords, unit_cell_inv.T)\n",
    "\n",
    "def objective_function(params, old_cell_params, old_cartesian_coords, new_cartesian_coords):\n",
    "    a_new, b_new, c_new, alpha_new, beta_new, gamma_new = params\n",
    "    a_old, b_old, c_old, alpha_old, beta_old, gamma_old = old_cell_params\n",
    "\n",
    "    # Compute transformation matrix for the old unit cell\n",
    "    T_old = unit_cell_to_cartesian_matrix(a_old, b_old, c_old, alpha_old, beta_old, gamma_old)\n",
    "    T_old_inv= np.linalg.inv(T_old)\n",
    "    #backup\n",
    "    old_fractional_coords = cartesian_to_fractional(old_cartesian_coords, T_old_inv)\n",
    "\n",
    "    # Compute transformation matrix for the new unit cell\n",
    "    T_new = unit_cell_to_cartesian_matrix(a_new, b_new, c_new, alpha_new, beta_new, gamma_new)\n",
    "    T_new_inv= np.linalg.inv(T_new)\n",
    "\n",
    "    # Convert the new Cartesian coordinates to fractional coordinate using the old unit cell\n",
    "    fractional_coords_new = cartesian_to_fractional(new_cartesian_coords, T_new_inv)\n",
    "\n",
    "    # Minimize the difference between the calculated new Cartesian coordinates and the provided new Cartesian coordinates\n",
    "    return np.sum(np.linalg.norm(fractional_coords_new - old_fractional_coords, axis=1)**2)\n",
    "\n",
    "# Example usage\n",
    "# Old cell parameters (example values)\n",
    "old_cell_params = [a, b, c, ang_alpha, ang_beta, ang_gamma]  # [a, b, c, alpha, beta, gamma]\n",
    "\n",
    "# Old Cartesian coordinates of points (example values)\n",
    "old_cartesian_coords = np.array([\n",
    "    [0.0, 0.0, 0.0],    # Point 1\n",
    "    [2.5, 3.0, 3.5],    # Point 2\n",
    "    [1.25, 1.5, 5.25],  # Point 3\n",
    "    [0.5, 2.4, 4.9]     # Point 4\n",
    "])\n",
    "\n",
    "\n",
    "# New Cartesian coordinates of the same points (example values)\n",
    "new_cartesian_coords = np.array([\n",
    "    [0.0, 0.0, 0.0],    # Point 1\n",
    "    [5, 6, 7],    # Point 2\n",
    "    [2.5, 3, 10.5],    # Point 3\n",
    "    [1, 4.8, 9.8]     # Point 4\n",
    "])\n",
    "\n",
    "# Initial guess for new unit cell parameters (e.g., slightly modified cell)\n",
    "initial_params = [4.5, 4.5, 4.5, 90.0, 90.0, 90.0]\n",
    "\n",
    "# Bounds: a, b, c > 0; angles [0, 180]\n",
    "bounds = [(0, None)] * 3 + [(20, 180)] * 3\n",
    "\n",
    "# Optimize using L-BFGS-B to minimize the objective function\n",
    "result = minimize(\n",
    "    objective_function,\n",
    "    x0=initial_params,\n",
    "    args=(old_cell_params, old_cartesian_coords, new_cartesian_coords),\n",
    "    method='L-BFGS-B',\n",
    "    bounds=bounds\n",
    ")\n",
    "\n",
    "# Extract optimized parameters\n",
    "optimized_params = np.round(result.x,5)\n",
    "print(\"Optimized New Cell Parameters:\", optimized_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_rotations_to_atom_positions(optimized_params, G, atom_positions):\n",
    "    num_nodes = len(G.nodes())\n",
    "    optimized_rotations = optimized_params.reshape(num_nodes, 3, 3)  # Reshape the optimized params into rotation matrices\n",
    "    \n",
    "    rotated_positions = {}\n",
    "    \n",
    "    for i, node in enumerate(G.nodes()):\n",
    "        rotation_matrix = optimized_rotations[i]\n",
    "        \n",
    "        # Debugging: Check properties of the rotation matrix\n",
    "        print(f\"Node {node} - Rotation Matrix:\\n{rotation_matrix}\")\n",
    "        \n",
    "        # Check if the matrix is orthogonal: R^T R should equal the identity matrix\n",
    "        orthogonality_check = np.dot(rotation_matrix.T, rotation_matrix)\n",
    "        print(f\"Node {node} - R^T R (should be identity):\\n{orthogonality_check}\")\n",
    "        \n",
    "        # Check determinant\n",
    "        determinant = np.linalg.det(rotation_matrix)\n",
    "        print(f\"Node {node} - Determinant of Rotation Matrix: {determinant}\")\n",
    "        \n",
    "        if not np.isclose(determinant, 1.0):\n",
    "            print(f\"Warning: Rotation matrix for Node {node} may not be a valid rotation (det = {determinant})\")\n",
    "        \n",
    "        # Get the original atom positions for this node\n",
    "        original_positions = atom_positions[node]\n",
    "        \n",
    "        # Calculate the center of mass (COM) for the node\n",
    "        com = np.mean(original_positions, axis=0)  # Mean of all atoms' positions in this node\n",
    "        print(f\"Node {node} - COM: {com}\")\n",
    "        \n",
    "        # Translate atom positions so that COM is at the origin\n",
    "        translated_positions = original_positions - com\n",
    "        print(f\"Node {node} - Translated Positions (COM at origin):\\n{translated_positions}\")\n",
    "        \n",
    "        # Apply rotation around the COM (rotate the translated positions)\n",
    "        rotated_translated_positions = np.dot(translated_positions, rotation_matrix.T)  # Rotate the translated positions\n",
    "        print(f\"Node {node} - Rotated Positions:\\n{rotated_translated_positions}\")\n",
    "        \n",
    "        # Translate back to the original position by adding COM\n",
    "        rotated_positions[node] = rotated_translated_positions + com\n",
    "        print(f\"Node {node} - Final Rotated Positions:\\n{rotated_positions[node]}\")\n",
    "        \n",
    "    return rotated_positions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0), (1, 1), (2, 2), (3, 3)]\n",
      "[(0, 0), (1, 1), (2, 2), (3, 3)]\n",
      "[(0, 0), (1, 1), (2, 2), (3, 3)]\n",
      "[(0, 0), (1, 1), (2, 2), (3, 3)]\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =           36     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.43425D+04    |proj g|=  5.45697D-04\n",
      "Optimized Pairings (after optimization):\n",
      "Node 0 and Node 2:\n",
      "  node0_0 -- node2_0\n",
      "  node0_1 -- node2_1\n",
      "  node0_2 -- node2_2\n",
      "  node0_3 -- node2_3\n",
      "Node 0 and Node 3:\n",
      "  node0_0 -- node3_0\n",
      "  node0_1 -- node3_1\n",
      "  node0_2 -- node3_2\n",
      "  node0_3 -- node3_3\n",
      "Node 1 and Node 2:\n",
      "  node1_0 -- node2_0\n",
      "  node1_1 -- node2_1\n",
      "  node1_2 -- node2_2\n",
      "  node1_3 -- node2_3\n",
      "Node 1 and Node 3:\n",
      "  node1_0 -- node3_0\n",
      "  node1_1 -- node3_1\n",
      "  node1_2 -- node3_2\n",
      "  node1_3 -- node3_3\n",
      "\n",
      "\n",
      "At iterate    1    f=  1.43425D+04    |proj g|=  5.45697D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "   36      1     14      1     0     0   5.457D-04   1.434D+04\n",
      "  F =   14342.468037679995     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize, linear_sum_assignment\n",
    "import networkx as nx\n",
    "\n",
    "def find_optimal_pairings(node_i_positions, node_j_positions):\n",
    "    \"\"\"\n",
    "    Find the optimal one-to-one pairing between atoms in two nodes using the Hungarian algorithm.\n",
    "    \"\"\"\n",
    "    num_i, num_j = len(node_i_positions), len(node_j_positions)\n",
    "    cost_matrix = np.zeros((num_i, num_j))\n",
    "    for i in range(num_i):\n",
    "        for j in range(num_j):\n",
    "            cost_matrix[i, j] = np.linalg.norm(node_i_positions[i] - node_j_positions[j])\n",
    "\n",
    "    row_ind, col_ind = linear_sum_assignment(cost_matrix)\n",
    "    print(list(zip(row_ind, col_ind)))\n",
    "    return list(zip(row_ind, col_ind))\n",
    "\n",
    "def find_edge_pairings(G, atom_positions):\n",
    "    \"\"\"\n",
    "    Identify optimal pairings for each edge in the graph.\n",
    "\n",
    "    Parameters:\n",
    "        G (networkx.Graph): Graph structure with edges between nodes.\n",
    "        atom_positions (dict): Positions of X atoms for each node.\n",
    "\n",
    "    Returns:\n",
    "        dict: Mapping of edges to optimal atom pairs.\n",
    "              Example: {(0, 1): [(0, 3), (1, 2)], ...}\n",
    "    \"\"\"\n",
    "    edge_pairings = {}\n",
    "\n",
    "    for i, j in G.edges():\n",
    "        node_i_positions = atom_positions[i]\n",
    "        node_j_positions = atom_positions[j]\n",
    "\n",
    "        # Find optimal pairings for this edge\n",
    "        pairs = find_optimal_pairings(node_i_positions, node_j_positions)\n",
    "        edge_pairings[(i, j)] = pairs\n",
    "\n",
    "\n",
    "    return edge_pairings\n",
    "\n",
    "\n",
    "def reorthogonalize_matrix(matrix):\n",
    "    \"\"\"\n",
    "    Ensure the matrix is a valid rotation matrix with determinant = 1.\n",
    "    \"\"\"\n",
    "    U, _, Vt = np.linalg.svd(matrix)\n",
    "    R = np.dot(U, Vt)\n",
    "    if np.linalg.det(R) < 0:\n",
    "        U[:, -1] *= -1\n",
    "        R = np.dot(U, Vt)\n",
    "    return R\n",
    "\n",
    "def compute_rotation_with_pairing(node_i_positions, node_j_positions, current_rotation_matrix):\n",
    "    \"\"\"\n",
    "    Compute the optimal rotation matrix for node pairs, starting from the current rotation matrix.\n",
    "    \n",
    "    Parameters:\n",
    "        node_i_positions (numpy.ndarray): Positions of X atoms in node i (Nx3 array).\n",
    "        node_j_positions (numpy.ndarray): Positions of X atoms in node j (Mx3 array).\n",
    "        current_rotation_matrix (numpy.ndarray): The current 3x3 rotation matrix for node i.\n",
    "\n",
    "    Returns:\n",
    "        rotation_matrix (numpy.ndarray): Optimized 3x3 rotation matrix for node i.\n",
    "    \"\"\"\n",
    "    # Find optimal one-to-one pairings between the atoms\n",
    "    pairs = find_optimal_pairings(node_i_positions, node_j_positions)\n",
    "    \n",
    "    # Extract paired positions\n",
    "    paired_i = np.array([node_i_positions[i] for i, _ in pairs])\n",
    "    paired_j = np.array([node_j_positions[j] for _, j in pairs])\n",
    "\n",
    "    # Compute the centers of mass for both sets\n",
    "    com_i = np.mean(paired_i, axis=0)\n",
    "    com_j = np.mean(paired_j, axis=0)\n",
    "\n",
    "    # Translate positions to the center of mass\n",
    "    translated_i = paired_i - com_i\n",
    "    translated_j = paired_j - com_j\n",
    "\n",
    "    # Apply the current rotation matrix to node_i's positions\n",
    "    rotated_translated_i = np.dot(translated_i, current_rotation_matrix.T)\n",
    "\n",
    "    # Compute covariance matrix and SVD\n",
    "    H = np.dot(rotated_translated_i.T, translated_j)\n",
    "    U, _, Vt = np.linalg.svd(H)\n",
    "    R = np.dot(U, Vt)\n",
    "\n",
    "    # Ensure the resulting matrix is a valid rotation matrix (det = 1)\n",
    "    if np.linalg.det(R) < 0:\n",
    "        U[:, -1] *= -1\n",
    "        R = np.dot(U, Vt)\n",
    "\n",
    "    # Update the rotation matrix by combining the current and incremental rotation\n",
    "    optimized_rotation_matrix = np.dot(R, current_rotation_matrix)\n",
    "\n",
    "    return optimized_rotation_matrix\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def objective_function(params, G, atom_positions, edge_pairings):\n",
    "    \"\"\"\n",
    "    Objective function to minimize distances between paired atoms along edges.\n",
    "\n",
    "    Parameters:\n",
    "        params (numpy.ndarray): Flattened array of rotation matrices.\n",
    "        G (networkx.Graph): Graph structure.\n",
    "        atom_positions (dict): Original positions of X atoms for each node.\n",
    "        edge_pairings (dict): Precomputed pairings for each edge.\n",
    "\n",
    "    Returns:\n",
    "        float: Total distance metric to minimize.\n",
    "    \"\"\"\n",
    "    num_nodes = len(G.nodes())\n",
    "    rotation_matrices = params.reshape(num_nodes, 3, 3)\n",
    "    total_distance = 0.0\n",
    "\n",
    "    for (i, j), pairs in edge_pairings.items():\n",
    "        R_i = reorthogonalize_matrix(rotation_matrices[i])\n",
    "        R_j = reorthogonalize_matrix(rotation_matrices[j])\n",
    "\n",
    "        com_i = np.mean(atom_positions[i], axis=0)\n",
    "        com_j = np.mean(atom_positions[j], axis=0)\n",
    "\n",
    "        # Rotate positions around their mass center\n",
    "        rotated_i_positions = np.dot(atom_positions[i] - com_i, R_i.T) + com_i\n",
    "        rotated_j_positions = np.dot(atom_positions[j] - com_j, R_j.T) + com_j\n",
    "\n",
    "        for idx_i, idx_j in pairs:\n",
    "            dist = np.linalg.norm(rotated_i_positions[idx_i] - rotated_j_positions[idx_j])\n",
    "            total_distance += dist ** 2\n",
    "\n",
    "    return total_distance\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def optimize_rotations(G, atom_positions):\n",
    "    \"\"\"\n",
    "    Optimize rotations for all nodes in the graph.\n",
    "\n",
    "    Parameters:\n",
    "        G (networkx.Graph): Graph structure with edges between nodes.\n",
    "        atom_positions (dict): Positions of X atoms for each node.\n",
    "\n",
    "    Returns:\n",
    "        list: Optimized rotation matrices for all nodes.\n",
    "    \"\"\"\n",
    "    num_nodes = len(G.nodes())\n",
    "    initial_rotations = np.tile(np.eye(3), (num_nodes, 1)).flatten()\n",
    "\n",
    "    # Precompute edge-specific pairings\n",
    "    edge_pairings = find_edge_pairings(G, atom_positions)\n",
    "\n",
    "    result = minimize(\n",
    "        objective_function,\n",
    "        initial_rotations,\n",
    "        args=(G, atom_positions, edge_pairings),\n",
    "        method=\"L-BFGS-B\",\n",
    "        options={\"maxiter\": 1000, \"disp\": True}\n",
    "    )\n",
    "\n",
    "    \n",
    "\n",
    "    optimized_rotations = result.x.reshape(num_nodes, 3, 3)\n",
    "    optimized_rotations = [reorthogonalize_matrix(R) for R in optimized_rotations]\n",
    "    \n",
    "    # Print the optimized pairings after optimization\n",
    "    print(\"Optimized Pairings (after optimization):\")\n",
    "    for (i, j), pairs in edge_pairings.items():\n",
    "        print(f\"Node {i} and Node {j}:\")\n",
    "        for idx_i, idx_j in pairs:\n",
    "            print(f\"  node{i}_{idx_i} -- node{j}_{idx_j}\")\n",
    "    print()\n",
    "\n",
    "    return optimized_rotations\n",
    "\n",
    "def apply_rotations_to_atom_positions(optimized_rotations, G, atom_positions):\n",
    "    \"\"\"\n",
    "    Apply the optimized rotation matrices to the atom positions.\n",
    "\n",
    "    Parameters:\n",
    "        optimized_rotations (list): Optimized rotation matrices for each node.\n",
    "        G (networkx.Graph): Graph structure.\n",
    "        atom_positions (dict): Original positions of X atoms for each node.\n",
    "\n",
    "    Returns:\n",
    "        dict: Rotated positions for each node.\n",
    "    \"\"\"\n",
    "    rotated_positions = {}\n",
    "\n",
    "    for i, node in enumerate(G.nodes()):\n",
    "        R = optimized_rotations[i]\n",
    "        original_positions = atom_positions[node]\n",
    "        com = np.mean(original_positions, axis=0)\n",
    "\n",
    "        # Translate, rotate, and translate back to preserve the mass center\n",
    "        translated_positions = original_positions - com\n",
    "        rotated_translated_positions = np.dot(translated_positions, R.T)\n",
    "        rotated_positions[node] = rotated_translated_positions + com\n",
    "\n",
    "    return rotated_positions\n",
    "\n",
    "\n",
    "def save_xyz(filename, rotated_positions):\n",
    "    \"\"\"\n",
    "    Save the rotated positions to an XYZ file for visualization.\n",
    "    \"\"\"\n",
    "    with open(filename, \"w\") as file:\n",
    "        num_atoms = sum(len(positions) for positions in rotated_positions.values())\n",
    "        file.write(f\"{num_atoms}\\n\")\n",
    "        file.write(\"Optimized structure\\n\")\n",
    "\n",
    "        for node, positions in rotated_positions.items():\n",
    "            for pos in positions:\n",
    "                file.write(f\"X {pos[0]:.4f} {pos[1]:.4f} {pos[2]:.4f}\\n\")\n",
    "\n",
    "# Example Usage\n",
    "# Define xxxxatom positions for each node\n",
    "xxxx_positions_dict = {}\n",
    "for i in range(len(nodexxxx)):\n",
    "    xxxx_positions_dict[i]=nodexxxx[i]\n",
    "# Defina all node positions \n",
    "chain_node_positions_dict = {}\n",
    "for i in range(len(chain_node_positions)):\n",
    "    chain_node_positions_dict[i]=chain_node_positions[i]\n",
    "\n",
    "\n",
    "\n",
    "G = nx.Graph()\n",
    "G.add_nodes_from(list(xxxx_positions_dict))\n",
    "G.add_edges_from([(0, 2), (0, 3),(1, 2), (1, 3)])  # Define a graph with 3 nodes and edges\n",
    "\n",
    "\n",
    "\n",
    "# Optimize rotations\n",
    "optimized_rotations = optimize_rotations(G, xxxx_positions_dict)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Apply rotations\n",
    "rotated_positions = apply_rotations_to_atom_positions(optimized_rotations, G, chain_node_positions_dict)\n",
    "\n",
    "# Save results to XYZ\n",
    "save_xyz(\"optimized_structure.xyz\", rotated_positions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "\n",
    "def find_edge_pairings(G, atom_positions):\n",
    "    \"\"\"\n",
    "    Identify optimal pairings for each edge in the graph.\n",
    "\n",
    "    Parameters:\n",
    "        G (networkx.Graph): Graph structure with edges between nodes.\n",
    "        atom_positions (dict): Positions of X atoms for each node.\n",
    "\n",
    "    Returns:\n",
    "        dict: Mapping of edges to optimal atom pairs.\n",
    "              Example: {(0, 1): [(0, 3), (1, 2)], ...}\n",
    "    \"\"\"\n",
    "    edge_pairings = {}\n",
    "\n",
    "    for i, j in G.edges():\n",
    "        node_i_positions = atom_positions[i]\n",
    "        node_j_positions = atom_positions[j]\n",
    "\n",
    "        # Find optimal pairings for this edge\n",
    "        pairs = find_optimal_pairings(node_i_positions, node_j_positions)\n",
    "        edge_pairings[(i, j)] = pairs\n",
    "\n",
    "\n",
    "    return edge_pairings\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def optimal_assignments_for_all_rounds(workers, rounds_of_companies):\n",
    "    \"\"\"\n",
    "    Assign workers to companies for multiple rounds, ensuring optimal assignment in each round.\n",
    "\n",
    "    Parameters:\n",
    "        workers (np.ndarray): Positions of workers, shape (num_workers, 2).\n",
    "        rounds_of_companies (list): List of company positions for each round,\n",
    "                                    each element is an np.ndarray of shape (num_companies, 2).\n",
    "\n",
    "    Returns:\n",
    "        list: List of assignments for each round, with total costs.\n",
    "    \"\"\"\n",
    "    all_assignments = []\n",
    "    for round_idx, companies in enumerate(rounds_of_companies):\n",
    "        # Compute the cost matrix (Euclidean distances)\n",
    "        cost_matrix = np.linalg.norm(workers[:, np.newaxis, :] - companies[np.newaxis, :, :], axis=2)\n",
    "\n",
    "        # Solve the assignment problem\n",
    "        worker_indices, company_indices = linear_sum_assignment(cost_matrix)\n",
    "\n",
    "        # Compute the total cost for this round\n",
    "        total_cost = cost_matrix[worker_indices, company_indices].sum()\n",
    "\n",
    "        # Store the results for this round\n",
    "        assignments = [(worker, company) for worker, company in zip(worker_indices, company_indices)]\n",
    "        all_assignments.append({\n",
    "            \"round\": round_idx,\n",
    "            \"assignments\": assignments,\n",
    "            \"total_cost\": total_cost,\n",
    "        })\n",
    "\n",
    "    return all_assignments\n",
    "\n",
    "# Example data\n",
    "workers = np.array([[1, 2], [3, 4], [5, 6]])  # Fixed worker positions\n",
    "\n",
    "# Multiple rounds of company positions\n",
    "rounds_of_companies = [\n",
    "    np.array([[2, 2], [4, 4], [6, 6]]),  # Round 1 companies\n",
    "    np.array([[1, 3], [3, 5], [5, 7]]),  # Round 2 companies\n",
    "    np.array([[2, 1], [4, 3], [6, 5]]),  # Round 3 companies\n",
    "]\n",
    "\n",
    "# Run the optimization\n",
    "results = optimal_assignments_for_all_rounds(workers, rounds_of_companies)\n",
    "\n",
    "# Output the results\n",
    "for result in results:\n",
    "    print(f\"Round {result['round']}:\")\n",
    "    print(f\"  Assignments: {result['assignments']}\")\n",
    "    print(f\"  Total cost: {result['total_cost']:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vlx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
